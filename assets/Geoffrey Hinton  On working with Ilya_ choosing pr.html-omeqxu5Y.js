import{_ as n,c as r,o,a as t,b as s}from"./app-BYXnI_A4.js";const e={},p=t("h1",{id:"杰弗里·辛顿-关于与-ilya-合作、选择问题以及直觉的力量-youtube",tabindex:"-1"},[t("a",{class:"header-anchor",href:"#杰弗里·辛顿-关于与-ilya-合作、选择问题以及直觉的力量-youtube"},[t("span",null,"杰弗里·辛顿 |关于与 Ilya 合作、选择问题以及直觉的力量 - YouTube")])],-1),a=t("div",{style:{position:"relative",width:"100%","padding-top":"56.25%"}},[t("iframe",{src:"https://www.youtube.com/embed/n4IQOBka8bc",style:{position:"absolute",top:"0",left:"0",width:"100%",height:"100%"},frameborder:"0",allow:"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share",referrerpolicy:"strict-origin-when-cross-origin",allowfullscreen:""})],-1),g=s('<h2 id="_1-视频核心内容" tabindex="-1"><a class="header-anchor" href="#_1-视频核心内容"><span>1. 视频核心内容</span></a></h2><p>本视频记录了Geoffrey Hinton与Joel Hellermark之间的一次深入对话，该对话于2024年4月在英国伦敦的皇家研究所进行。视频中，Hinton分享了他与Ilya Sutskever的合作经历，选择研究问题的方法，以及直觉在科研中的重要性。他详细阐述了自己对神经网络、人工智能以及大脑工作机制的深刻见解，并讨论了AI技术的发展对社会可能产生的影响。</p><h3 id="_1-1-与ilya-sutskever的合作" tabindex="-1"><a class="header-anchor" href="#_1-1-与ilya-sutskever的合作"><span>1.1 与Ilya Sutskever的合作</span></a></h3><p>Hinton回忆了与Ilya Sutskever的初次相遇，当时Ilya是一名对神经网络充满热情的学生。他们的合作始于Ilya对梯度优化方法的独特见解，这一见解后来成为了深度学习领域的一个重要突破。Hinton赞扬了Ilya的数学能力和独立思考的能力，认为这些特质是推动科学进步的重要因素。</p><h3 id="_1-2-选择研究问题的方法" tabindex="-1"><a class="header-anchor" href="#_1-2-选择研究问题的方法"><span>1.2 选择研究问题的方法</span></a></h3><p>Hinton提到，他在选择研究问题时，往往依赖于直觉。他寻找那些看似普遍接受但自己感觉不对的观点，然后深入研究以揭示其潜在的问题。他举例说明了如何通过简单的计算机模拟来展示某些普遍观点的错误，这种方法帮助他在神经网络的研究中取得了突破。</p><h3 id="_1-3-直觉在科研中的作用" tabindex="-1"><a class="header-anchor" href="#_1-3-直觉在科研中的作用"><span>1.3 直觉在科研中的作用</span></a></h3><p>Hinton强调了直觉在科学研究中的重要性。他认为，直觉是科学家在面对复杂问题时的一种重要工具，能够帮助他们识别出问题的关键点。他分享了自己如何依赖直觉来指导研究方向，并鼓励年轻科学家培养和发展自己的直觉。</p><h3 id="_1-4-ai技术的发展及其社会影响" tabindex="-1"><a class="header-anchor" href="#_1-4-ai技术的发展及其社会影响"><span>1.4 AI技术的发展及其社会影响</span></a></h3><p>Hinton讨论了AI技术的发展对社会的潜在影响，包括在医疗保健、教育和技术创新等领域的应用。他同时也表达了对AI可能被滥用的担忧，并呼吁科学家和政策制定者共同努力，确保AI技术的发展能够造福人类社会。</p><h3 id="_1-5-对未来的展望" tabindex="-1"><a class="header-anchor" href="#_1-5-对未来的展望"><span>1.5 对未来的展望</span></a></h3><p>在视频的最后，Hinton分享了他对未来AI研究的展望。他提到了对大脑如何进行学习的持续好奇，特别是大脑如何实现类似于反向传播的机制。他认为，理解这一点将是未来AI研究的关键，并可能带来技术上的重大突破。</p><p>通过这次对话，Hinton不仅展示了他作为AI领域先驱的深刻见解，也提供了对未来科研方向的宝贵建议。他的经验和智慧对于所有对人工智能感兴趣的人来说都是一笔宝贵的财富。</p><h2 id="_2-作者核心观点" tabindex="-1"><a class="header-anchor" href="#_2-作者核心观点"><span>2. 作者核心观点</span></a></h2><ul><li><p><strong>对大脑学习的理解</strong>：作者早期对大脑的学习机制感到失望，因为传统的生理学和哲学教育并未提供深入的理解。他转向人工智能，特别是神经网络，以模拟和测试大脑的理论。</p></li><li><p><strong>神经网络的发展</strong>：作者与Ilya Sutskever的合作对神经网络的发展产生了重要影响。Ilya的直觉和创新思维，如对梯度优化的独特见解，推动了神经网络技术的进步。</p></li><li><p><strong>计算规模的重要性</strong>：作者认识到，随着数据和计算能力的增加，神经网络的性能显著提升。他提到了一个实验，其中使用大规模数据和计算资源成功实现了字符级别的预测。</p></li><li><p><strong>语言模型的理解能力</strong>：作者认为，通过预测下一个符号，语言模型实际上是在进行一定程度的推理和理解。他强调，这些模型不仅仅是简单的文本组合，而是能够进行复杂的信息处理。</p></li><li><p><strong>多模态学习的潜力</strong>：作者预测，结合视觉和语言等多模态信息将使AI更好地理解空间关系和物体操作，从而提高其推理能力。</p></li><li><p><strong>对未来AI的展望</strong>：作者认为，随着模型规模的增大，AI将能够进行更复杂的推理，并可能超越人类的知识水平。他强调了AI在医疗健康等领域的应用潜力，同时也表达了对AI可能被滥用的担忧。</p></li><li><p><strong>个人成就与反思</strong>：作者对自己在Boltzmann机器学习算法上的贡献感到自豪，并反思了科学研究中好奇心驱动的本质。他强调，尽管AI技术带来了巨大的社会影响，但科学家的主要动力应是对未知的好奇和探索。</p></li></ul><h2 id="_3-专业知识" tabindex="-1"><a class="header-anchor" href="#_3-专业知识"><span>3. 专业知识</span></a></h2><h3 id="_3-1-神经网络的学习机制" tabindex="-1"><a class="header-anchor" href="#_3-1-神经网络的学习机制"><span>3.1 神经网络的学习机制</span></a></h3><ul><li><strong>梯度优化</strong>：Ilya提出的关于梯度优化的独特视角，质疑为何不将梯度直接提供给一个合理的函数优化器。</li><li><strong>模型规模与性能</strong>：Ilya早期就主张通过增加模型规模来提升性能，这与后来的实践证明相符，尽管Hinton最初对此持怀疑态度。</li></ul><h3 id="_3-2-语言模型的训练与理解" tabindex="-1"><a class="header-anchor" href="#_3-2-语言模型的训练与理解"><span>3.2 语言模型的训练与理解</span></a></h3><ul><li><strong>字符级预测模型</strong>：2011年，Hinton与Ilya及James Martins合作，使用字符级预测模型处理Wikipedia数据，展示了模型的理解能力。</li><li><strong>语言模型的理解深度</strong>：Hinton认为，通过预测下一个符号，模型实际上在理解语言，这与传统的自动完成机制有本质区别。</li></ul><h3 id="_3-3-多模态学习" tabindex="-1"><a class="header-anchor" href="#_3-3-多模态学习"><span>3.3 多模态学习</span></a></h3><ul><li><strong>空间理解</strong>：引入图像和视频等多模态数据，可以显著提高模型对空间关系的理解能力。</li><li><strong>模型的综合能力</strong>：多模态学习不仅增强了对单一模态的理解，还能促进模型在不同模态间的推理和整合能力。</li></ul><h3 id="_3-4-计算硬件的影响" tabindex="-1"><a class="header-anchor" href="#_3-4-计算硬件的影响"><span>3.4 计算硬件的影响</span></a></h3><ul><li><strong>GPU的应用</strong>：Hinton在2006年意识到GPU在处理矩阵乘法方面的优势，这极大地加速了神经网络的训练过程。</li><li><strong>模拟计算的探索</strong>：Hinton在Google的最后几年，研究了模拟计算在降低能耗方面的潜力，尽管这一尝试未能成功。</li></ul><h3 id="_3-5-认知与语言的关系" tabindex="-1"><a class="header-anchor" href="#_3-5-认知与语言的关系"><span>3.5 认知与语言的关系</span></a></h3><ul><li><strong>语言与认知的三种观点</strong>：Hinton提出了关于语言与认知的三种不同理解方式，从符号处理到向量嵌入，再到介于两者之间的模型。</li><li><strong>语言模型的认知能力</strong>：Hinton认为，通过向量嵌入和符号交互，语言模型能够实现对语言的深入理解，这与人类认知过程有相似之处。</li></ul><h3 id="_3-6-快速权重与学习机制" tabindex="-1"><a class="header-anchor" href="#_3-6-快速权重与学习机制"><span>3.6 快速权重与学习机制</span></a></h3><ul><li><strong>快速权重</strong>：Hinton提到，大脑可能使用快速权重作为临时记忆，这与现有的神经网络模型中使用的慢速权重形成对比。</li><li><strong>多时间尺度学习</strong>：大脑中存在的多时间尺度学习机制，可能为神经网络的学习机制提供新的研究方向。</li></ul><p>这些专业知识点涵盖了从基础的神经网络学习理论到高级的多模态学习和计算硬件的应用，展示了Hinton在人工智能领域的深刻见解和前瞻性思考。</p><h2 id="_4-举一反三" tabindex="-1"><a class="header-anchor" href="#_4-举一反三"><span>4.举一反三</span></a></h2><h4 id="_1-geoffrey-hinton如何看待选择研究问题的方法" tabindex="-1"><a class="header-anchor" href="#_1-geoffrey-hinton如何看待选择研究问题的方法"><span>1. Geoffrey Hinton如何看待选择研究问题的方法？</span></a></h4><p>Geoffrey Hinton选择研究问题的方法是寻找那些大多数人认同的观点，但直觉上感觉不对的问题。他会深入研究这些问题，尝试通过简单的计算机程序演示来展示这些观点的错误之处。例如，他提到大多数人认为向神经网络添加噪声会降低其性能，但实际上这样做可以提高其泛化能力。他通过这种方式来挑战和探索传统观念，从而推动科学研究的进步。</p><h4 id="_2-hinton如何评价他在研究生涯中最自豪的成就" tabindex="-1"><a class="header-anchor" href="#_2-hinton如何评价他在研究生涯中最自豪的成就"><span>2. Hinton如何评价他在研究生涯中最自豪的成就？</span></a></h4><p>Hinton最自豪的成就是开发了Boltzmann机器的学习算法。他认为这个算法非常优雅和简洁，尽管在实际应用中可能不太实用。他与Terry Sejnowski合作开发的这个算法，虽然可能不是最终正确的方向，但他对此感到非常自豪。这个成就体现了Hinton对科学美学的追求和对复杂问题深入探索的精神。</p><h4 id="_3-hinton如何看待人工智能在医疗健康领域的应用前景" tabindex="-1"><a class="header-anchor" href="#_3-hinton如何看待人工智能在医疗健康领域的应用前景"><span>3. Hinton如何看待人工智能在医疗健康领域的应用前景？</span></a></h4><p>Hinton认为人工智能在医疗健康领域有巨大的应用潜力。他提到，如果每个人都能拥有多个医生级别的AI助手，这将极大地改善医疗服务的质量和可及性。他强调，随着AI技术的进步，我们可以在需要大量专业知识的领域，如医疗，实现更高效和更广泛的服务。这不仅能够提高医疗服务的质量，还能够帮助解决医疗资源分配不均的问题。</p><h2 id="_5-访谈内容" tabindex="-1"><a class="header-anchor" href="#_5-访谈内容"><span>5. 访谈内容</span></a></h2><p><strong>杰弗里·辛顿：</strong> 所以我记得我第一次从英格兰来到卡耐基梅隆的时候，那时是6点，你们会去卡耐基马伦的酒吧喝一杯。我记得我在那里呆了几周之后，那是一个星期六的夜晚。我还没有任何朋友，也不知道该怎么办，所以我决定去实验室做一些编程，因为我有一台列表机，你不能在家里编程。所以我在一个星期六晚上9点左右进入实验室，实验室正在蜂拥而出。所有的学生都在那里，他们都在那里，因为他们正在为未来而努力。他们都相信他们接下来所做的事情将改变计算机科学的进程。这和英格兰是如此的不同。所以这非常令人耳目一新。</p><p><strong>主持人：</strong> 带我回到最开始，杰夫在剑桥，试图理解大脑，那是什么样子？</p><p><strong>杰弗里·辛顿：</strong> 这非常令人失望，所以我学了生理学，在夏季学期，他们将教我们大脑如何工作。他们教给我们的只是神经元如何进行动作电位，这非常有趣，但它并不能告诉你大脑是如何工作的。所以这非常令人失望。我转向哲学，然后我想也许他们会告诉我们思想是如何运作的，这非常令人失望。我最终去了爱丁堡做AI，这更有趣。至少你可以模拟事情，这样你就可以测试理论了。</p><p><strong>主持人：</strong> 你还记得是什么让你对AI感兴趣吗？这是一篇论文吗？是某个特定的人让你接触到了这些想法吗？</p><p><strong>杰弗里·辛顿：</strong> 我想是唐纳德赫布写的一本书对我影响很大。他对如何学习神经网络中的连接强度非常感兴趣。我早些时候也读了一本约翰·冯·诺伊曼写的书，他对大脑计算以及它与普通计算机的不同非常感兴趣。</p><p><strong>主持人：</strong> 你是否确信这些想法在那时会奏效，或者你在爱丁堡时代的直觉是什么？</p><p><strong>杰弗里·辛顿：</strong> 在我看来，大脑必须有一种学习的方式，而且显然不是通过将各种各样的东西编入程序然后使用逻辑推理规则来学习的。在我看来，这从一开始就很疯狂，所以我们必须弄清楚大脑如何学会修改神经网络中的连接，以便它可以做复杂的事情。冯·诺伊曼也相信这一点。图灵相信这一点。所以冯·诺伊曼和图灵都很擅长逻辑，但他们不相信这种逻辑方法。</p><p><strong>主持人：</strong> 你在研究神经科学的思想和仅仅做看似好的人工智能算法之间有什么分歧？你早期获得了多少灵感？</p><p><strong>杰弗里·辛顿：</strong> 所以我从来没有做过这么多的神经科学研究。我总是受到我所了解的大脑工作原理的启发，那就是有一堆神经元，它们执行相对简单的操作，它们是非线性的，但它们收集输入，对它们加权，然后根据加权输入给出输出。问题是，你如何改变这些权重以使整个事情做得很好？这似乎是一个相当简单的问题。</p><p><strong>主持人：</strong> 你记得从那个时候开始的哪些合作？</p><p><strong>杰弗里·辛顿：</strong> 我在卡耐基梅隆的主要合作对象是不在卡耐基梅隆的人。我经常和特里·西诺夫斯基互动，他在巴尔的摩的约翰霍普金斯大学，大约每月一次，要么他开车去匹兹堡，要么我开车去巴尔的摩。这是250英里远的地方，我们将一起度过一个周末，研究玻尔兹曼机。这是一次美妙的合作。我们都相信这就是大脑的工作方式。这是你做过的最令人兴奋的研究，许多技术成果非常有趣，但我认为这不是大脑的工作方式。</p><p><strong>杰弗里·辛顿：</strong> 我也与彼得·布朗有很好的合作，他是一位非常优秀的统计学家，他在IBM从事语音识别工作，然后他作为一个更成熟的学生来到卡内基梅隆大学攻读博士，但他已经知道了很多，他教会了我很多关于演讲的知识，实际上，他教了我关于隐藏的马尔可夫模型。我认为我从他身上学到的比他从我身上学到的更多。这就是你想要的那种学生，当他教我关于隐藏的马尔可夫模型时，我正在使用隐藏层进行反向支持，只是它们当时不被称为隐藏层。我决定他们使用的名称是隐藏的马尔科夫模型，对于你不知道它们在做什么的变量来说，这是一个很好的名称。这就是隐藏在神经网络中的名字的来源。我和彼得认为这是一个很好的名字，因为它们被隐藏为神经网络，但我从彼得那里学到了很多关于语音的知识。</p><p><strong>主持人：</strong> 带我们回到埃莉娅出现在你办公室的时候。</p><p><strong>杰弗里·辛顿：</strong> 我在我的办公室。我可能会在一个星期日，我正在编程，我想，然后有人敲门。不仅仅是任何敲门声，但它不会切割，这是一个紧急的敲门声。所以我去应门，这是一个年轻的学生，他说他在夏天做薯条，但他宁愿在我的实验室工作。所以我说，好吧，你为什么不预约一下，我们谈谈。所以当你说，现在怎么样？这就是莉娅的性格。所以我们谈了一会儿，我给了他一篇关于反向传播的自然论文，我们一周后又开了一次会议，他回来说，我不理解，我非常失望。</p><p><strong>杰弗里·辛顿：</strong> 我认为他看起来是个聪明的人，但这只是链式规则，并不难理解。他说，哦，不，不，我明白了，我只是不明白为什么你不把梯度交给一个明智的函数优化器，这让我们考虑了好几年。而且它继续这样下去，特别是这样。他的直觉很好，他对事物的原始直觉总是很好。</p><p><strong>主持人：</strong> 你认为是什么让埃莉娅有了这些直觉？</p><p><strong>杰弗里·辛顿：</strong> 我不知道，我想他总是为自己考虑，他从小就对AI感兴趣，他显然擅长数学，所以，但很难知道。</p><p><strong>主持人：</strong> 你们两个之间的合作是什么？比如，你会扮演什么角色，埃莉娅会扮演什么角色？</p><p><strong>杰弗里·辛顿：</strong> 这很有趣。我记得有一次，当我们试图做一个复杂的事情来生成数据地图时，我有一种混合模型，这样你就可以把同样的一些相似之处变成两个地图，以便在一个地图库中可以接近贪婪，在另一个地图库中可以接近河流，因为在一张地图中，你不能让它靠近两者，对吧？因为河流和贪婪相隔很远。所以我们会有各种地图。</p><p><strong>杰弗里·辛顿：</strong> 我们在Matlab中做这件事，这涉及到大量代码的重组，以进行正确的矩阵乘法。然后你就受够了。所以有一天他来了，说我要为Matlab写一个接口。所以我用这种不同的语言编程，然后我有一些东西可以把它转换成Matlab。我说，不，伊利亚，那需要你一个月的时间。我们必须继续这个项目。不要因此而分心。伊利亚说，没关系，我今天早上做的。</p><p><strong>主持人：</strong> 这太不可思议了。在那些年里，最大的转变不一定仅仅是算法，还包括技能。查看这项技能。多年来。</p><p><strong>杰弗里·辛顿：</strong> 伊利亚很早就有了这种直觉。所以Ilia一直在说教，你只要把它做大，它就会更有效。我一直认为这有点像在自窥自窥自窥自窥自窥自窥自窥自窥自窥自窥自窥自窥自窥自窥自窥自窥自窥自窥自窥自窥自窥自窥自窥自窥自窥自窥自窥自窥自窥自窥自窥自窥自窥自窥自窥自窥自窥自窥自窥自窥自窥自窥自窥自窥自窥自窥自窥到。你也必须有新的想法。事实证明意大利基本上是正确的，新的想法有所帮助。像变压器这样的东西帮助了很多，但实际上是数据的规模和计算的规模。那时，我们不知道计算机会变得比现在快十亿倍。我们以为他们可能会快100倍。我们试图通过提出聪明的想法来做事，如果我们有更大的数据和计算规模，这些想法本可以自己解决。</p><p><strong>杰弗里·辛顿：</strong> 大约在2011年，Ilya和另一位研究生James Martins和我写了一篇使用字符级别预测的论文。所以我们拿维基百科来预测下一个HTML字符，效果非常好，我们总是惊讶于它的效果，那就是在Gpu上使用了一个奇特的优化器。我们从未完全相信它理解任何东西，但看起来好像它理解了，而且看起来不可思议。</p><p><strong>主持人：</strong> 你能告诉我们这些模型是如何预测下一个单词的趋势的，以及为什么这是错误的思考方式吗？</p><p><strong>杰弗里·辛顿：</strong> 好吧，我真的不相信这是错误的方式吗？所以实际上，我认为我做了第一个使用嵌入和反向传播的神经网络语言模型。所以这非常简单。数据只是三倍，它将每个符号转换成一个嵌入，然后让嵌入进行交互以预测下一个符号的嵌入，然后从中预测下一个符号。然后在整个过程中反向传播来学习这些三元组。我展示了它可以泛化，大约10年后，yosho benja使用了一个非常相似的网络，并展示了它与真实文本的协同工作。大约10年后，语言学家开始相信嵌入。这是一个缓慢的过程。</p><p><strong>杰弗里·辛顿：</strong> 我认为它不仅仅是预测下一个符号的原因是，如果你问，预测下一个符号需要什么？特别是如果你问我一个问题，然后答案的第一个单词是下一个符号，你必须理解这个问题。所以我认为通过预测下一个符号，它非常不像老式的自动完成和老式的自动完成，你会存储三倍的单词。然后，如果您看到一对单词，您会发现不同的单词经常出现在第三位。在那里你可以预测下一个符号。这就是大多数人认为自动完成的样子。它不再是那样的了。</p><p><strong>杰弗里·辛顿：</strong> 要预测下一个符号，你必须理解已经说过的话。所以我认为你通过让它预测下一个符号来迫使它理解，我认为它的理解方式与我们大致相同。所以很多人会告诉你这些事情不像我们，他们只是在预测下一个符号。他们不像我们一样推理，但实际上，为了预测下一个符号，它将不得不进行一些推理。我们现在已经看到，如果你在不做任何特殊的东西进行推理的情况下做出大的，他们已经可以做一些推理了。我认为随着你让他们变得更大，他们将能够做越来越多的推理。</p><p><strong>主持人：</strong> 你认为我现在除了预测下一个符号外，还在做其他事情吗？</p><p><strong>杰弗里·辛顿：</strong> 我认为这就是你学习的方式。我认为你正在预测下一个视频帧，你正在预测下一个声音。但我认为这是一个关于大脑如何学习的相当合理的理论。</p><p><strong>主持人：</strong> 是什么让这些模型能够学习如此广泛的领域？</p><p><strong>杰弗里·辛顿：</strong> 这些大型语言模型正在做的是寻找公共结构。通过找到共同的结构，他们可以使用共同的结构对事物进行编码，这更有效。</p><p><strong>杰弗里·辛顿：</strong> 让我给你举个例子。如果你问GPT-4，为什么堆肥堆像原子弹？大多数人无法回答这个问题。大多数人没有想到他们认为原子弹和堆肥是非常不同的东西。但GPT-4会告诉你，能量尺度非常不同，时间尺度也非常不同。但相同的是，当堆肥堆变得更热时，它会更快地产生热量。当原子弹产生更多中子时，它会更快地产生更多中子。所以它得到了连锁反应的想法。我相信它们都是连锁反应的形式。它正在使用这种理解将所有信息压缩到其权重中。</p><p><strong>杰弗里·辛顿：</strong> 如果它正在这样做，那么它将在数百个我们还没有看到类比的事情上这样做，但它已经这样做了。这就是你从中获得创造力的地方，从显然非常不同的事物之间的类比中看到。所以我认为当它变得更大的时候，GPT-4会变得非常有创意。</p><p><strong>杰弗里·辛顿：</strong> 我认为这个想法只是重复学习它学到的东西，只是拼凑在一起，文本已经学习了。这是完全错误的。它将比人更有创造力。</p><p><strong>主持人：</strong> 我想你会争辩说，它不仅会重复我们迄今为止开发的人类知识，还可能超越这一点。我认为这是我们还没有完全看到的事情。我们已经开始看到一些这样的例子，但在很大程度上，我们仍然处于当前的科学水平。你认为什么能让它超越？</p><p><strong>杰弗里·辛顿：</strong> 好吧，我们在更有限的背景下看到了这一点。就像在和丽莎娃娃的著名比赛中，阿尔法·高做出了37号动作，所有专家都说这一定是错误的，但后来他们意识到这是一个聪明的举动。所以这是在有限的领域内的创意，我认为随着这些事情的发展，我们会看到更多的创意。</p><p><strong>主持人：</strong> 与AlphaGo的不同之处在于，它使用的强化学习随后使其能够超越当前状态。因此，它从模仿学习开始，观察人类如何玩游戏，然后通过自我游戏，发展到超越这一点。你认为这是当前数据库中缺失的部分吗？</p><p><strong>杰弗里·辛顿：</strong> 我认为这可能是一个缺失的组成部分，是的，AlphaGo和Alpha 0中的自我游戏是为什么它可以做出这些创造性举动的很大一部分原因，但我认为这不是完全必要的。</p><p><strong>杰弗里·辛顿：</strong> 所以我很久以前做了一个小实验，训练一个神经网络识别手写数字。我喜欢那个例子，MNIST例子。你给它训练数据，其中一半的答案是错误的。问题是，它学得有多好？你一旦把一半的答案弄错，就这样保留下去。所以它不能仅仅通过看到相同的例子来平均错误，但是有时候正确的答案，有时候错误的答案，当它看到例子一半的例子时，它说例子，答案总是错误的。</p><p><strong>杰弗里·辛顿：</strong> 因此训练数据有50% 的误差。但是如果你训练反向传播，它会降低到5% 或更少的误差。换句话说，从错误标记的数据中，它可以获得更好的结果。</p><p><strong>杰弗里·辛顿：</strong> 它可以看到训练数据是错误的，这就是聪明的学生可以比他们的顾问更聪明的原因。他们的顾问告诉了他们所有这些东西。他们的导师告诉他们的一半，他们认为不是垃圾，然后他们听另一半，然后他们比导师更聪明。所以这些大型神经网络实际上可以做到，它们可以比它们的训练数据做得更好，大多数人没有意识到这一点。</p><p><strong>主持人：</strong> 那么你希望这些模型如何加入推理呢？所以我的意思是，一种方法是在它们之上添加某种启发式方法，现在很多研究都在这样做，在你有思维链的地方，你只是将其推理反馈到它本身。另一种方式是模型本身，当你放大它时，你的直觉是什么？</p><p><strong>杰弗里·辛顿：</strong> 所以我的直觉是，随着我们扩大这些模型的规模，我的推理能力会越来越好。如果你问人们是如何工作的，粗略地说，我们有这些直觉，我们可以进行推理。我们使用推理来纠正我们的直觉。当然，我们在推理过程中使用直觉来进行推理。但是如果推理的结论与我们的直觉相冲突，我们意识到直觉需要改变。这就像在alpha go或alpha 0中一样，你有一个评估函数，它只是看着棋盘并说，这对我有多好？然后你进行了蒙特卡罗的推广，现在你得到了更准确的想法，你可以修改你的评估函数。所以你可以通过让它与推理的结果相一致来训练它。</p><p><strong>杰弗里·辛顿：</strong> 我认为这些大型语言模型必须开始这样做。他们必须开始训练他们关于接下来应该发生什么的原始直觉，通过推理并意识到这是不正确的。这样一来，他们可以获得更多的训练数据，而不仅仅是模仿人们所做的事情。这就是为什么AlphaGo可以做出这个创造性的举动37的原因。它有更多的训练数据，因为它使用推理来检查正确的下一步应该是什么。</p><p><strong>主持人：</strong> 你对多模态有什么看法？所以我们谈到了这些类比。而且通常这些类比远远超出了我们的能力范围。它正在发现远远超出人类的类比，也许在抽象层面上，我们现在永远无法理解，当我们引入图像、视频和声音时，你认为这将如何改变模型？你认为它将如何改变它能够做出的类比？</p><p><strong>杰弗里·辛顿：</strong> 我认为它会改变很多。我认为这将使它更好地理解空间事物，例如，仅从语言中理解一些空间事物是相当困难的，尽管GPT-4甚至在它被多模态之前就可以做到这一点。但是当你让它多模态时，如果你既有视觉又有伸手抓住东西，如果你能捡起并翻转它们等等，它就会更好地理解物体。因此，尽管你可以从语言中学到很多东西，但如果你模糊了模态，学习起来会更容易，事实上，你需要更少的语言。还有很多用于预测下一帧或类似内容的YouTube视频。所以我认为这些多模态模式显然会接管市场。你可以通过这种方式获取更多数据，他们需要的语言更少。因此，有一个真正的哲学观点，你可以仅从一种语言中学习一个非常好的模型，但从多模态系统中学习它要容易得多。</p><p><strong>主持人：</strong> 你认为它会如何影响模型的推理？</p><p><strong>杰弗里·辛顿：</strong> 我认为这将使它在推理空间方面做得更好，例如，推理如果你捡起物体会发生什么。如果你真的试着捡起物品，你会得到各种各样的训练目标，这会有所帮助。</p><p><strong>主持人：</strong> 你认为人类的大脑进化到能够很好地处理语言吗？或者你认为语言进化到能够与人类大脑很好地协同工作吗？</p><p><strong>杰弗里·辛顿：</strong> 我认为是语言进化来与大脑合作，还是大脑进化来与语言合作，这是一个非常好的问题。我想两者都发生了。我曾经认为我们可以在完全不需要语言的情况下进行大量的认知。现在我有点改变了想法，所以让我给你三个不同的语言观点以及它与认知的关系。</p><p><strong>杰弗里·辛顿：</strong> 有一种老式的符号观，即认知包括以某种清理干净的逻辑语言拥有符号串，在其中没有歧义并应用推理规则。这就是认知。这只是对事物的象征性操作，就像语言符号的字符串一样。这是一种极端的观点。一个相反的极端观点是，一旦你进入了头脑，它就是所有矢量。所以符号进来，你把这些符号转换成大矢量，里面所有的东西都是用大矢量完成的。然后，如果你想产生输出，你可以再次产生符号。</p><p><strong>杰弗里·辛顿：</strong> 因此，大约在2014年，人们在使用神经循环神经网络时出现了一个机器翻译点。而具有隐藏状态的单词将继续进入，并且它们在这种隐藏状态中不断积累信息。因此，当他们到达一个句子的末尾时，这个句子有一个大的隐藏向量，可以捕捉该句子的含义，这可以用于用另一种语言生成被称为思想向量的句子。</p><p><strong>杰弗里·辛顿：</strong> 这是语言的第二种观点。你将语言转换成一个大向量，它与语言完全不同，这就是认知的意义。但是还有第三种观点，这就是我现在所相信的，即你拿走这些符号，然后将符号转换为嵌入，然后使用多层。所以你得到了这些非常丰富的嵌入，但嵌入仍然绑定到感知中的符号，你有一个大向量用于这个符号，一个大向量用于那个符号。这些向量相互作用，生成下一个单词的符号向量。这就是理解的意义，理解是知道如何将符号转换为这些向量，并知道向量的元素如何交互以预测下一个符号的向量。这就是理解，无论是在这些大型语言模型中还是在我们的大脑中。</p><p><strong>杰弗里·辛顿：</strong> 这是一个介于两者之间的例子。你停留在符号中，但你将它们作为这些大矢量。这就是所有的工作和知识都在使用什么向量以及这些向量的元素如何相互作用，而不是符号规则。但这并不是说你完全摆脱了这个符号。它是说你把符号变成了大矢量，但你仍然保持符号的表面结构，这就是这些模型的工作方式。而且现在在我看来，这也是一个更合理的人类思维模型。</p><p><strong>主持人：</strong> 你是第一个想到使用Gpu的人之一，我知道Jensen爱你。回到2009年，你提到你告诉过你，这对于训练神经网络来说可能是一个非常好的想法。带我们回到使用Gpus训练神经网络的早期直觉。</p><p><strong>杰弗里·辛顿：</strong> 实际上，我想大约在2006年，我有一个名叫Rick zeliska的前研究生，他是一位非常优秀的计算机视觉专家。我和他在一次会议上交谈，他说，你知道，你应该考虑使用图形处理卡，因为它们非常擅长矩阵乘法。你所做的基本上是所有的矩阵乘法。所以我想了一会儿。然后我们了解了这些具有四个Gpu的特斯拉系统，最初我们只是使用游戏Gpu，并发现它们使速度提高了30倍。然后我们购买了其中一个带有四个Gpu的特斯拉系统。我们对此进行了演讲，效果非常好。</p><p><strong>杰弗里·辛顿：</strong> 然后在2009年，我在Nips上做了一个演讲，我告诉1000名机器学习研究人员，你们都应该去购买视频Gpu。他们是未来。你需要他们来做机器学习。实际上，我随后给Nvidia发邮件说，我告诉1000名机器学习研究人员购买您的电路板。你能给我一个免费的吗？他们说，不，实际上，他们并没有拒绝，只是没有回复。但是当我后来告诉Jensen这个故事时，他给了我一个免费的。</p><p><strong>主持人：</strong> 非常好。我认为有趣的是，Gpus是如何与该领域一起发展的。那么你认为我们接下来应该去哪里计算呢？</p><p><strong>杰弗里·辛顿：</strong> 所以我在谷歌的最后几年，我一直在思考如何尝试进行模拟计算。因此，我们可以像大脑一样使用30瓦，而不是像兆瓦那样使用。我们可以在模拟硬件中运行这些大型语言模型。我从来没有成功过，但我开始真正欣赏数字计算。</p><p><strong>杰弗里·辛顿：</strong> 因此，如果您要使用低功耗模拟计算，每个硬件都会有所不同。这个想法是学习将利用硬件的特定属性。这就是发生在人们身上的事情。我们所有的大脑都是不同的。所以我们不能把你大脑中的重量放到我的大脑中，硬件是不同的。各个神经元的精确属性是不同的。学习已经学会了利用所有这些，所以我们在感知中是凡人，因为我大脑中的权重对其他任何大脑都没有好处。当我死了，那些重量都没用了。</p><p><strong>杰弗里·辛顿：</strong> 我们可以通过产生句子并找出如何改变权重来低效地从一个到另一个获取信息。所以你会说同样的话，那叫做蒸馏，但这是一种非常低效的知识交流方式。使用数字系统，它们是不朽的，因为一旦你有了一些重量，你就可以扔掉电脑。只需将权重存储在磁带上的某个地方，然后再建另一台计算机，放入相同的权重，如果它是数字的，它可以计算出与其他系统完全相同的事情。因此，数字系统可以共享权重，如果你有一大堆数字系统，它们每个都去做一点学习，并且它们从相同的权重开始，做一点学习，然后再次共享权重，那么效率会高得多。他们都知道所有其他人所做的事情，我们无法做到这一点，因此他们在分享知识方面远远优于我们。</p><p><strong>主持人：</strong> 很多在该领域部署的想法都是非常古老的学校ID。这是一直存在于神经科学中的Ids。你认为剩下什么可以应用到我们开发的系统中？</p><p><strong>杰弗里·辛顿：</strong> 因此，我们仍然需要赶上神经科学的一件大事是变化的时间尺度。几乎所有的神经网络。有一个快速的时间尺度来改变活动。因此，输入来自活动，嵌入向量全部发生变化，然后有一个缓慢的时间尺度，它正在改变权重，这就是长期学习，大脑中只有这两个时间尺度，权重变化的时间尺度很多。</p><p><strong>杰弗里·辛顿：</strong> 因此，例如，如果我说了一个像黄瓜这样意想不到的单词，现在五分钟后你戴上耳机，会有很多噪音，而且有非常微弱的单词，你会更擅长识别黄瓜这个单词，因为我五分钟前就说过了。那么这些知识在大脑中的哪个位置，而这些知识显然是突触的暂时变化。进入的不是神经元。黄瓜，黄瓜，黄瓜。你没有足够的神经元。它是暂时改变权重，你可以快速进行很多临时权重变化，我称之为快速权重。我们在这些神经模型中不这样做，我们不这样做的原因是因为如果你临时改变了依赖于输入数据的权重，那么你就不能同时处理一大堆不同的情况。</p><p><strong>杰弗里·辛顿：</strong> 目前，我们将一大堆不同的字符串堆叠在一起，并行处理它们，因为这样我们可以进行矩阵乘法，效率更高。正是这种效率阻止了我们使用快速权重。但大脑显然使用快速权重来进行临时记忆。嗯，有各种各样的事情你可以这样做，而我们目前不做。</p><p><strong>杰弗里·辛顿：</strong> 我认为这是你必须学习的最重要的事情之一。我非常希望像图形核心这样的东西，如果他们按顺序进行在线学习，那么他们就可以使用快速权重，但这还没有奏效。我认为当人们使用电导进行配重时，最终会成功的。</p><p><strong>主持人：</strong> 知道这些模型是如何工作的，知道大脑是如何工作的，对你的思维方式有什么影响？</p><p><strong>杰弗里·辛顿：</strong> 我认为有一个很大的影响，它是在相当抽象的层面上，那就是多年来，人们对拥有一个大的随机神经网络的想法非常蔑视，只是给你很多训练数据。</p><p><strong>杰弗里·辛顿：</strong> 如果你与统计学家、语言学家或大多数从事AI的人交谈，它会学会做复杂的事情，他们说这只是一个白日梦。如果没有某种天生的天赋，没有很多建筑限制，你就无法学习真正复杂的东西。事实证明这是完全错误的。你可以使用一个大的随机神经网络，并仅从数据中学习一大堆东西。因此，使用随机梯度下降来重复调整权重的想法使用梯度来学习东西并学习复杂的东西，这已经被这些大模型验证了。</p><p><strong>杰弗里·辛顿：</strong> 这是关于大脑非常重要的一件事。它不必拥有所有这些天生的结构。现在，显然，它有很多天生的结构，但对于那些容易学习的东西，它肯定不需要天生的结构。所以，来自查姆斯基的想法是，你不会，你不会学习像语言这样复杂的东西，除非它已经有各种各样的连接并且成熟起来。这个想法现在显然是无稽之谈。</p><p><strong>主持人：</strong> 我相信，查姆斯基会感激你称他的想法为无稽之谈。</p><p><strong>杰弗里·辛顿：</strong> 嗯，我认为实际上，我认为很多查姆斯基的政治思想是非常明智的。我总是感到震惊的是，为什么一个对中东有如此明智的想法的人在语言学方面可能会如此错误。</p><p><strong>主持人：</strong> 你认为这些模型如何更有效地模拟人类的意识？但是想象一下，你有和你交谈过的AI助手。而不是那个存在，你知道，像Sha一样，这会删除对话的记忆，你一直重新开始。它有自我反思。在某个时候，你去世了，你告诉助手。</p><p><strong>杰弗里·辛顿：</strong> 你觉得呢？我的意思是，不是我，是别人说的。</p><p><strong>主持人：</strong> 是的，你很难把这个告诉助手。你认为那个助理此时会有什么感觉？是的。</p><p><strong>杰弗里·辛顿：</strong> 我认为他们也可以有感情。所以我认为就像我们有感知的内部剧院模型一样，我们也有情感的内部剧院模型。这些是我能经历的事情，但其他人不能。我认为这种模式同样是错误的。所以我想，假设我说，我觉得我想在鼻子上打余凯杰（Gary），我经常这样做。让我们试着将其从内部剧院的概念中抽象出来。</p><p><strong>杰弗里·辛顿：</strong> 我真正想说的是，如果不是来自我额叶的抑制，我会做出一个动作。所以当我们谈论感受时，我们真正谈论的是如果没有限制我们将采取的行动。这真的，这就是感觉，如果没有限制，我们会采取的行动。所以我认为你可以对感情给出同样的解释，而且没有理由这些东西不能有感情。</p><p><strong>杰弗里·辛顿：</strong> 事实上，在1973年，我看到一个机器人有一种情感。所以在爱丁堡，他们有一个机器人，有两个这样的夹子，如果你把这些零件分别放在一块绿色的毛毡上，就可以组装一辆玩具车。但如果你想把它们堆成一堆，他的视力不够好，无法弄清楚发生了什么。所以它把他的剧本放进去，好像被重击了一样，结果让他们大吃一惊。所以它们被分散，然后它将它们耦合在一起。如果你在一个人身上看到这一点，你会说它与情况交叉，因为它不理解它，所以它摧毁了它。</p><p><strong>主持人：</strong> 这太深奥了。当我们之前交谈时，你描述了人类和流血排放物。你认为你一生中发现的最有力的类比是什么？</p><p><strong>杰弗里·辛顿：</strong> 哦，贯穿我的一生。我猜，可能是一种对我影响很大的弱类比，就是宗教信仰和符号处理信仰之间的类比。所以当我很小的时候，我遇到了来自一个无神论家庭的问题，我上了学，遇到了宗教信仰的问题。对我来说，这似乎是无稽之谈。对我来说，这似乎仍然是无稽之谈。当我看到符号处理作为人们如何工作的解释时，我认为这只是同样的无稽之谈。</p><p><strong>杰弗里·辛顿：</strong> 我现在不认为这是非常无稽之谈，因为我认为实际上我们确实在进行符号处理。我们只是通过给符号提供这些大的嵌入向量来做到这一点，但我们实际上是在进行符号处理，而不是像人们认为的那样匹配符号。一个符号唯一的区别是它与另一个符号相同或不相同。这是符号唯一的属性。我们根本不这样做。我们使用上下文给符号赋予嵌入向量，然后利用这些嵌入向量的分量之间的交互来进行思考。</p><p><strong>杰弗里·辛顿：</strong> 但是谷歌有一位非常优秀的研究员，名叫费尔南多·佩雷拉，他说，是的，我们确实有符号推理，我们唯一的符号就是自然语言。自然语言是一种符号语言，我们用它来推理。我现在相信。</p><p><strong>主持人：</strong> 你已经完成了计算机科学史上一些最有意义的研究。你能告诉我们如何选择正确的问题来解决吗？</p><p><strong>杰弗里·辛顿：</strong> 首先，让我纠正你。我和我的学生做了很多最有意义的事情，主要是与学生的良好合作和我选择优秀学生的能力。这是因为在70、80、90和2000年代很少有人在做神经网络。因此，少数从事神经网络研究的人必须挑选最优秀的学生。所以这是一件幸运的事情。</p><p><strong>杰弗里·辛顿：</strong> 但我选择问题的方式基本上是，当科学家谈论它们如何工作时，他们会有关于它们如何工作的理论，这可能与事实没有太大关系。但我的理论是，我寻找一些每个人都同意的东西，但感觉不对。只是有一种轻微的直觉，有些不对劲。然后我研究它，看看我是否可以详细阐述为什么会这样。</p><p><strong>杰弗里·辛顿：</strong> 我认为这是错误的。也许我可以用一个小的计算机程序做一个小演示，说明它不像你期望的那样工作。</p><p><strong>杰弗里·辛顿：</strong> 让我举一个例子。大多数人认为，如果向神经网络添加噪音，效果会更糟。例如，每次训练一个样本时，一半的神经元都保持沉默，效果会更糟。实际上，我们知道。如果你这样做，会更容易概括。你可以用一个简单的例子来证明这一点。这就是计算机模拟的好处。你可以展示，你知道，你的这个想法是，增加噪音会让情况变得更糟，而一半的神经元脱落会让它的工作变得更糟，这在短期内会发生。但如果你像那样训练它，最终它会更有效。</p><p><strong>杰弗里·辛顿：</strong> 你可以用一个小的计算机程序来证明这一点，然后你可以认真思考为什么会这样，以及它如何阻止大的复杂的共同适应。但是我认为这是我的工作方法，听起来很可疑，然后继续努力，看看你能否简单地证明为什么它是错误的。</p><p><strong>主持人：</strong> 你现在觉得可疑吗？</p><p><strong>杰弗里·辛顿：</strong> 好吧，我们不使用快速体重听起来很可疑，我们只有这两个时间尺度，这是错误的。这一点都不像大脑。从长远来看，我认为我们将不得不进行更多的时间扫描。这就是一个例子。</p><p><strong>主持人：</strong> 如果你有，如果你今天有一群学生来找你，他们问了我们之前讨论过的那个汉明问题，你知道你所在领域最重要的问题是什么？你有什么建议要承担和努力？混合？我们谈到了推理时间和技能。你会给他们最高优先级的问题是什么？</p><p><strong>杰弗里·辛顿：</strong> 现在对我来说，这是我过去30年左右一直面临的相同问题，即大脑是否会反向传播？我相信大脑正在获得梯度。如果你没有得到梯度，你的学习能力就会比你得到梯度时差很多。但是大脑是如何获得梯度的呢？它是否以某种方式实现了某种近似版本的反向传播？或者这是完全不同的技术？这是一个很大的开放性问题。如果我继续做研究，那就是我要做的研究。</p><p><strong>主持人：</strong> 当你现在回顾你的职业生涯时，你在很多事情上都是正确的，但你错在哪里，你希望自己花更少的时间追求某个方向？</p><p><strong>杰弗里·辛顿：</strong> 好的，这是两个不同的问题。一个是，你错了什么？第二，你希望花更少的时间在这上面吗？我认为我对博尔顿机器的看法是错误的，我很高兴我花了很长时间在这上面。它们是关于如何获得梯度的一个比反向传播更美丽的理论。反向传播是普通而合理的，它只是一个可链的过程。螺栓机器很聪明，这是一种非常有趣的获取梯度的方法。我很希望大脑是这样工作的，但我认为不是这样。</p><p><strong>主持人：</strong> 你花了很多时间想象系统开发后会发生什么吗？你有没有想过，如果我们能让这个系统运作得很好，我们就可以，你知道的，让教育民主化，我们可以让知识更容易获取，我们可以解决医学中的一些棘手问题？还是更多关于理解大脑？</p><p><strong>杰弗里·辛顿：</strong> 是的，我有点觉得科学家应该做有助于社会的事情，但实际上这不是你最好的研究方式。当好奇心驱使下，你会做最好的研究。你只需要理解一些东西。最近，我意识到这些事情可能会造成很大的伤害，也会带来很多好处，我变得更加担心它们对社会的影响，但这并不是我的动力。我只是想了解大脑究竟是如何学会做事情的？这就是我想知道的。而我有点失败，这是失败的副作用。我们得到了一些不错的工程。</p><p><strong>主持人：</strong> 是的，这对世界来说是一个很好的失败。如果你把镜头对准那些可能真正成功的事情，你认为最有前途的应用是什么？</p><p><strong>杰弗里·辛顿：</strong> 我认为医疗保健显然是一个大问题。有了医疗保健，社会可以吸收多少医疗保健几乎没有尽头。如果你接受一位老人，他们可以全职请五位医生。所以当AI比人们做的更好时，你会希望你在那些可以做更多事情的领域变得更好，如果每个人都有三个自己的医生，我们可以做更多的医生，那就太好了。我们将达到那个点。这就是为什么医疗保健是好的原因之一。</p><p><strong>杰弗里·辛顿：</strong> 还有新工程，开发新材料，例如用于更好的太阳能电池板或超导或仅仅用于理解身体如何工作。Ram，那里将会有巨大的影响。这些都将是好事。我所担心的是，不良行为者使用它们做坏事。我们已经为普京、Z或特朗普这样的人提供了便利，将人工智能用于杀手机器人、操纵公众舆论或大规模监视，这些都是非常令人担忧的事情。</p><p><strong>主持人：</strong> 你是否担心过减慢场地速度也会降低积极因素的影响？</p><p><strong>杰弗里·辛顿：</strong> 哦，绝对的。我认为这个领域不太可能放缓，部分原因是它是国际性的。如果一个国家减速，其他国家就不会减速。所以中国和美国之间显然存在一场竞赛，而且这两个国家都不会放慢速度。所以，是的，我不，我的意思是，有个分区说我们应该放慢速度六个月。我没有签署它，因为我认为它永远不会发生。我也许应该签署它，因为即使它永远不会发生，它也有政治意义。通常，要求你知道的事情是件好事，你不能仅仅为了表明观点而要求。但我不认为我们会慢下来。</p><p><strong>主持人：</strong> 你认为这种援助会如何影响AI研究过程？</p><p><strong>杰弗里·辛顿：</strong> 我认为这会使效率更高。当你得到这些帮助来帮助你编程时，AI研究将变得更加高效，而且还可以帮助你思考问题，并且可能在方程方面也有很大帮助。</p><p><strong>主持人：</strong> 你对挑选人才的过程有反思吗？这对你来说大多是直观的，就像当伊利亚出现在门口时，你觉得这是一个聪明的人，让我们一起努力。</p><p><strong>杰弗里·辛顿：</strong> 因此，在挑选人才方面，有时你只是知道，在与伊利亚交谈不很长时间后，他似乎很聪明，然后说得更多，他显然非常聪明，直觉非常好，数学也很好。所以这是显而易见的。</p><p><strong>杰弗里·辛顿：</strong> 还有另一个例子，我在一次Nips会议上，有一张海报，有人走过来，他开始对海报提出问题，他问的每个问题都是对我们做错了什么的深刻见解。五分钟后，我向他提供了我的博士后职位。那个人就是大卫·麦凯，他很聪明，他死了很难过，但是他很明显你会在其他时候想要他，这并不那么明显。我学到的一件事是，人是不同的，并不只有一种类型的好学生。我觉得有些学生并没有那么有创造力，但是技术上非常强大，可以让任何事情都成功。还有其他学生技术不强，但很有创造力。当然，你想要两者兼而有之的人，但你并不总是能得到。但我认为实际上在实验室里，你需要各种不同类型的研究生，但我仍然用我的直觉，有时你和某人交谈，他们只是非常，非常，他们只是明白了。</p><p><strong>主持人：</strong> 那些就是你想要的。你认为有些人有更好的直觉的原因是什么？他们是否比其他人有更好的训练数据，或者你如何发展你的直觉？</p><p><strong>杰弗里·辛顿：</strong> 我认为部分原因是他们不代表无稽之谈。所以这里有一种获取不良直觉的方法。</p><p><strong>杰弗里·辛顿：</strong> 相信你被告知的一切，那是致命的。你必须能够，我想有些人会这样做，他们有一个完整的框架来理解现实，当有人告诉他们一些事情时，他们会试图找出如何适应他们的框架，如果没有，他们就会拒绝它。这是一个非常好的策略。那些试图将他们被告知的任何事情都纳入其中的人最终会得到一个非常模糊且可以相信一切的框架，这是无用的。所以我认为实际上拥有强烈的世界观，并试图操纵传入的事实以适应你的观点，显然它会导致你陷入深刻的宗教信仰和致命的缺陷等等，就像我对巴尔的摩机器的信仰一样。但我认为这是应该走的路。如果你有可以信任的良好直觉，你就应该信任。如果你直觉不好，你做什么都不重要，所以你最好相信他们。</p><p><strong>主持人：</strong> 这是一个非常好的观点。当你看到正在进行的研究类型时，你认为我们把所有的鸡蛋都放在一个篮子里，我们应该在这个领域更加多样化我们的想法吗？你认为这是最有前途的方向吗？那我们就全靠它吧。</p><p><strong>杰弗里·辛顿：</strong> 我认为拥有大型模型并在多模态数据上进行训练，即使只是为了预测下一个单词，这是一种非常有前途的方法，我们应该一直尝试。显然，现在有很多人在做这件事，也有很多人在做看似疯狂的事情，这很好。但我认为像大多数人一样走这条路没问题，因为它运作得非常好。</p><p><strong>主持人：</strong> 你认为学习算法有那么重要，还是只是一种技能？基本上是否有数百万种方式可以达到人类的智力水平，或者是否有一些我们需要发现的精选方法？</p><p><strong>杰弗里·辛顿：</strong> 是的，所以这个问题是否特定的学习算法非常重要，或者是否有各种各样的学习算法可以完成这项工作，我不知道答案。在我看来，反向传播有一个感知，它是正确的事情，获取梯度，这样你就可以改变参数，使其更好地工作。这似乎是正确的事情，而且取得了惊人的成功。可能还有其他学习算法可以替代获得相同梯度的方法，或者正在获得梯度或其他东西，而且也有效。</p><p><strong>杰弗里·辛顿：</strong> Ram，我想这都是开放的。现在有一个非常有趣的问题，关于是否有其他的事情可以尝试并最大化，从而为你提供良好的系统。也许大脑这样做是因为这样更容易。但是反向prop感知是正确的事情。我们知道这样做效果非常好。</p><p><strong>主持人：</strong> 最后一个问题，当你回顾你几十年的研究时，你最自豪的是什么，是学生还是研究？当你回顾自己一生的工作时，最让你感到自豪的是什么？</p><p><strong>杰弗里·辛顿：</strong> 博尔顿机器的学习算法。因此，玻尔兹曼机器中的学习算法非常优雅。在实践中我可能没有希望，但这是我最喜欢和特里一起发展的事情，也是我最自豪的事情，即使它是错误的。</p><p><strong>主持人：</strong> 你现在大部分时间都在思考哪些问题？是它。</p><p><strong>杰弗里·辛顿：</strong> 我应该在Netflix上看什么？</p><hr><p><strong>信息来源</strong></p><ul><li><a href="https://www.youtube.com/watch?v=n4IQOBka8bc&amp;t=486s" target="_blank" rel="noopener noreferrer">https://www.youtube.com/watch?v=n4IQOBka8bc&amp;t=486s</a></li></ul><p>内容由<a href="https://www.mix-copilot.com/" target="_blank" rel="noopener noreferrer">MiX Copilot</a>基于大语言模型生成，有可能存在错误的风险。</p>',159),i=[p,a,g];function l(h,c){return o(),r("div",null,i)}const _=n(e,[["render",l],["__file","Geoffrey Hinton  On working with Ilya_ choosing pr.html.vue"]]),u=JSON.parse('{"path":"/posts/interviews/people/%E6%9D%B0%E5%BC%97%E9%87%8C%C2%B7%E8%BE%9B%E9%A1%BF/Geoffrey%20Hinton%20%20On%20working%20with%20Ilya_%20choosing%20pr.html","title":"杰弗里·辛顿 |关于与 Ilya 合作、选择问题以及直觉的力量 - YouTube","lang":"en-US","frontmatter":{"description":"在2024年4月，Geoffrey Hinton与Joel Hellermark在伦敦皇家研究所进行了一场对话，讨论了人工智能的发展、合作经历以及直觉的力量。该对话在斯德哥尔摩的Sana AI峰会上进行了编辑版首映。","date":"2024/5/24 21:02:49","head":[["meta",{"property":"og:url","content":"https://xuezhirong.com/posts/interviews/people/%E6%9D%B0%E5%BC%97%E9%87%8C%C2%B7%E8%BE%9B%E9%A1%BF/Geoffrey%20Hinton%20%20On%20working%20with%20Ilya_%20choosing%20pr.html"}],["meta",{"property":"og:site_name","content":"薛志荣的知识库"}],["meta",{"property":"og:title","content":"杰弗里·辛顿 |关于与 Ilya 合作、选择问题以及直觉的力量 - YouTube"}],["meta",{"property":"og:description","content":"在2024年4月，Geoffrey Hinton与Joel Hellermark在伦敦皇家研究所进行了一场对话，讨论了人工智能的发展、合作经历以及直觉的力量。该对话在斯德哥尔摩的Sana AI峰会上进行了编辑版首映。"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"en-US"}],["meta",{"property":"article:author","content":"薛志荣"}],["meta",{"property":"article:published_time","content":"2024-05-24T13:02:49.000Z"}],["meta",{"property":"og:updated_time","content":"2024-07-01T09:11:29.546Z"}],["meta",{"property":"og:modified_time","content":"2024-07-01T09:11:29.546Z"}],["meta",{"name":"twitter:title","content":"杰弗里·辛顿 |关于与 Ilya 合作、选择问题以及直觉的力量 - YouTube"}],["meta",{"name":"twitter:description","content":"在2024年4月，Geoffrey Hinton与Joel Hellermark在伦敦皇家研究所进行了一场对话，讨论了人工智能的发展、合作经历以及直觉的力量。该对话在斯德哥尔摩的Sana AI峰会上进行了编辑版首映。"}],["meta",{"name":"twitter:card","content":"summary_large_image"}],["meta",{"name":"twitter:site","content":"XueZhirong"}],["meta",{"name":"twitter:creator","content":"XueZhirong"}],["meta",{"name":"share_config","content":"twitter,weibo,facebook,email"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"杰弗里·辛顿 |关于与 Ilya 合作、选择问题以及直觉的力量 - YouTube\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2024-05-24T13:02:49.000Z\\",\\"dateModified\\":null,\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"薛志荣\\"}]}"]]},"headers":[{"level":2,"title":"1. 视频核心内容","slug":"_1-视频核心内容","link":"#_1-视频核心内容","children":[{"level":3,"title":"1.1 与Ilya Sutskever的合作","slug":"_1-1-与ilya-sutskever的合作","link":"#_1-1-与ilya-sutskever的合作","children":[]},{"level":3,"title":"1.2 选择研究问题的方法","slug":"_1-2-选择研究问题的方法","link":"#_1-2-选择研究问题的方法","children":[]},{"level":3,"title":"1.3 直觉在科研中的作用","slug":"_1-3-直觉在科研中的作用","link":"#_1-3-直觉在科研中的作用","children":[]},{"level":3,"title":"1.4 AI技术的发展及其社会影响","slug":"_1-4-ai技术的发展及其社会影响","link":"#_1-4-ai技术的发展及其社会影响","children":[]},{"level":3,"title":"1.5 对未来的展望","slug":"_1-5-对未来的展望","link":"#_1-5-对未来的展望","children":[]}]},{"level":2,"title":"2. 作者核心观点","slug":"_2-作者核心观点","link":"#_2-作者核心观点","children":[]},{"level":2,"title":"3. 专业知识","slug":"_3-专业知识","link":"#_3-专业知识","children":[{"level":3,"title":"3.1 神经网络的学习机制","slug":"_3-1-神经网络的学习机制","link":"#_3-1-神经网络的学习机制","children":[]},{"level":3,"title":"3.2 语言模型的训练与理解","slug":"_3-2-语言模型的训练与理解","link":"#_3-2-语言模型的训练与理解","children":[]},{"level":3,"title":"3.3 多模态学习","slug":"_3-3-多模态学习","link":"#_3-3-多模态学习","children":[]},{"level":3,"title":"3.4 计算硬件的影响","slug":"_3-4-计算硬件的影响","link":"#_3-4-计算硬件的影响","children":[]},{"level":3,"title":"3.5 认知与语言的关系","slug":"_3-5-认知与语言的关系","link":"#_3-5-认知与语言的关系","children":[]},{"level":3,"title":"3.6 快速权重与学习机制","slug":"_3-6-快速权重与学习机制","link":"#_3-6-快速权重与学习机制","children":[]}]},{"level":2,"title":"4.举一反三","slug":"_4-举一反三","link":"#_4-举一反三","children":[]},{"level":2,"title":"5. 访谈内容","slug":"_5-访谈内容","link":"#_5-访谈内容","children":[]}],"git":{"updatedTime":null,"contributors":[]},"filePathRelative":"posts/interviews/people/杰弗里·辛顿/Geoffrey Hinton  On working with Ilya, choosing pr.md","excerpt":"\\n<div style=\\"position: relative; width: 100%; padding-top: 56.25%;\\"><iframe src=\\"https://www.youtube.com/embed/n4IQOBka8bc\\" style=\\"position: absolute; top: 0; left: 0; width: 100%; height: 100%;\\" frameborder=\\"0\\" allow=\\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\\" referrerpolicy=\\"strict-origin-when-cross-origin\\" allowfullscreen=\\"\\"></iframe></div>"}');export{_ as comp,u as data};
