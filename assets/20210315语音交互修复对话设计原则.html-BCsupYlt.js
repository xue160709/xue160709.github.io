import{_ as a}from"./fddb16800247da628472bb725fa12925_MD5-BBYypHVA.js";import{_ as c}from"./e2c4f05a19713c89a12623b9712217c8_MD5-tKA958om.js";import{_ as r,r as s,o as _,c as i,a as e,b as t,d as o,e as d}from"./app-CrMRnZWc.js";const p="/assets/8192c9568b20a870c8d03893505e835d_MD5-Dx7G-pcu.png",l="/assets/12e193ffa3b2ab667ddb7d0446ad591d_MD5-B_ZT5NHa.png",m="/assets/c568e097cd905e8bb042c37447648c7e_MD5-DzVKSxSv.png",b={},h=d('<p><img src="'+a+'" alt="cover_image"></p><h1 id="语音交互-修复对话设计原则" tabindex="-1"><a class="header-anchor" href="#语音交互-修复对话设计原则"><span>语音交互-修复对话设计原则</span></a></h1><p>人和人之间的对话失败有两种可能，一是双方缺少共同的认知背景；二是对话不符合“合作原则”导致错误的表意，但是人会本能地、实时地互相纠正，使对话回到正确的轨道上。在人机对话过程中计算机会把以上两种失败和纠正过程都识别为错误，除此之外，人说话时的犹豫行为会导致语音识别的超时问题，环境噪音导致语音识别出其他内容等因素会导致人机对话的失败。 对于机器编程产生的对话，设计师不要只将精力集中于所谓的“理想流程”和“预设逻辑”中。在对话过程中用户很难知道为什么出现了对话失败，更不可能知道在多层语音和语言识别系统复杂的结构中到底是哪里出现了错误。要使对话能够顺利进行，需要很多条件很好地结合在一起才能达成，包括语音信号处理、数据网络传输、自然语言理解等等，一旦一处地方不符合预期就会引发“出错”。所以设计师应该考虑并解决这些问题，例如设计相关的对白告知用户当前的状况是什么，提供修复错误的说明引导，使整个人机对话能够基于对话流和“合作原则”重回正轨。修复对话的关键在于学会站在机器视角来看待问题，以下4种常见情况会都会导致对话的失败： 1.机器没有获取到任何输入。可能是因为确实没有，也可能是系统没有检测到。结果就是造成系统获取信息超时。 2.虽然机器获取到了信息，但是却不能识别或解析，这种情况可能是因为背景噪音，或是有多个用户一起说话。 3.识别了用户的输入信息，但系统不知道如何去回应处理。例如用户可能会说：“我不知道怎么调整音量”，此时系统也许会错误地解析信息，无法正确的处理请求。 4.错误地识别了用户的输入信息，这种情况可能是最坏的一种结果。因为用户会被误导，而谈话会继续向错误的方向继续。 以上4种常见情况，我们总不能对用户说“我没听懂那句话”或是“抱歉我没理解”。一句“对不起”可能是最简单、最直接、成本最低的回复，但要避免过度使用。因为在大部分情况下都有比道歉更好的沟通方式，提供解决方案比道歉更有用。这时候我们可以考虑以下做法： 1.当用户超时输入或者无输入时，我们可以再次提示一遍用户刚才问的问题，这时可以用较为简洁的句式变体对原有问题进行二次询问，而不是每次都告诉用户“没有听到”或者“不明白”。 2.理解内容但不能提供帮助，这里分四种情况。第一种是智能助手不支持用户要求的功能时，我们可以使用说“我目前还不能帮助你做xx事”来告诉用户该功能不可用，但可能在将来支持。为了支持这点，我们需要提前计划要做的功能的意图。然后，我们可以跟踪用户何时请求不支持的功能，这能让我们更好的确定功能的优先级。例如用户想在订制旅程的技能中租车，如果不支持智能助手可以说：“我现在还不能帮你租车。但我可以帮你订制旅行，你想去哪个城市？” 第二种是用户说法不清导致意图识别信息缺失，这时候需要通过询问引导用户澄清一遍，完成必要槽位信息的补足。在询问过程中，建议列举相关内容供用户参考。例如用户需要打电话给朋友小王时，但小王有两个电话号码，这时候智能助手可以问：“小王有两个电话号码，请问你要打点给第一个还是第二个呢？” 第三种是由于阈值上下限的缘故，智能助手不能提供完整的帮助，这时候应该告诉用户当前状况并推荐相关操作。例如用户要调高空调的温度到100°C，或者想在30°C的基础上调高10°C，这时候智能助手可以说：“抱歉，当前空调最高温度为33°C，已经为你调到最高温度了。” 最后一种情况是明确知道用户的指令是错误的，需要引导用户重回正轨或者恢复默认状态。例如空调的吹风档位有1~4档，用户有可能太冷说了一句“关闭4档”。用户的潜意识是认为4档风量太大，他想把风量调低一点，但是用户不知道吹风档位意图识别上只有切换没有关闭的概念。所以我们应该提前想到用户的常用说法，并在意图设计和回复上体现出来，这时候智能助手可以回答：“吹风档位已经为你调回1档啦”。 3.由于各种原因导致识别不清晰，系统不知道用户说了什么。建议在兜底模块中首先通过关键字匹配和内容相似度的方式纠正指令，从而为用户解决问题。如果以上方法不可行，再对内容进行语法分析和关键字匹配，如果匹配上关键字可以交由FAQ模块或者第三方搜索模块来解决。如果没匹配上关键字，语法分析没太大问题可以交由闲聊模块解决，问题很大则告知用户“抱歉我没理解”（语句中语法有严重问题一般都是噪音导致）。 4.用户在多轮对话过程中没按剧本走导致理解出问题时，可以在多轮交互过程中提示用户目前所支持的说法是什么，限制用户的说法；或者询问用户是否退出当前多轮对话并进入新一轮对话中。 本章节的最后提供一份Google语音交互设计走查表，里面的内容包括问候语与结束语、对话的自然流畅、人物画像、对话修复/容错，它能为读者提供快速的检查方法，有效确保自己的设计是否合理。<br><img src="'+p+'" alt=""><img src="'+l+'" alt=""><img src="'+m+'" alt=""><strong>文章最后</strong> 最近笔者会抽空把第二本书中和语音交互设计相关的内容陆续更新到公众号，后续还有最后一部分内容《语音交互的GUI设计》。如果读者对本节内容有任何建议或者疑问，请在后台留言:-)</p>',3),g={href:"http://mp.weixin.qq.com/s?__biz=MzAxOTI4OTg3Mg==&mid=2649347686&idx=1&sn=7f45d5cae670677cc35e170f90c5136b&chksm=83d43419b4a3bd0f6eed52fa2c93202eef7764a13b4b91af117d0968296cb744dd552c8cec26&scene=21#wechat_redirect",target:"_blank",rel:"noopener noreferrer"},E=e("br",null,null,-1),f={href:"http://mp.weixin.qq.com/s?__biz=MzAxOTI4OTg3Mg==&mid=2649347691&idx=1&sn=d4a065608b39c165d5d7423313714025&chksm=83d43414b4a3bd02255695cb56d537d7447e671a4b9d497af78e9547eb88b7e4f003ac5cc9de&scene=21#wechat_redirect",target:"_blank",rel:"noopener noreferrer"},A=e("br",null,null,-1),x={href:"http://mp.weixin.qq.com/s?__biz=MzAxOTI4OTg3Mg==&mid=2649347524&idx=1&sn=d59d5ac05ee1e970479a89950c3a8468&chksm=83d437bbb4a3bead13994cafa2702575d37bf8527184fc435cb72c02f6c31a40ea4fa8a24c29&scene=21#wechat_redirect",target:"_blank",rel:"noopener noreferrer"},u=e("p",null,[e("img",{src:c,alt:""})],-1);function B(F,C){const n=s("ExternalLinkIcon");return _(),i("div",null,[h,e("p",null,[t("** 推荐阅读 ** "),e("a",g,[t(" 语音交互-对话设计原则 "),o(n)]),E,e("a",f,[t(" 语音交互-任务型对话设计原则 "),o(n)]),A,e("a",x,[t(" VGUI融合的三种实现方式 "),o(n)])]),u])}const M=r(b,[["render",B],["__file","20210315语音交互修复对话设计原则.html.vue"]]),w=JSON.parse('{"path":"/posts/blogs/HCI/20210315%E8%AF%AD%E9%9F%B3%E4%BA%A4%E4%BA%92%E4%BF%AE%E5%A4%8D%E5%AF%B9%E8%AF%9D%E8%AE%BE%E8%AE%A1%E5%8E%9F%E5%88%99.html","title":"语音交互-修复对话设计原则","lang":"en-US","frontmatter":{"description":"cover_image 语音交互-修复对话设计原则 人和人之间的对话失败有两种可能，一是双方缺少共同的认知背景；二是对话不符合“合作原则”导致错误的表意，但是人会本能地、实时地互相纠正，使对话回到正确的轨道上。在人机对话过程中计算机会把以上两种失败和纠正过程都识别为错误，除此之外，人说话时的犹豫行为会导致语音识别的超时问题，环境噪音导致语音识别出其他内...","head":[["meta",{"property":"og:url","content":"https://www.xuezhirong.com/posts/blogs/HCI/20210315%E8%AF%AD%E9%9F%B3%E4%BA%A4%E4%BA%92%E4%BF%AE%E5%A4%8D%E5%AF%B9%E8%AF%9D%E8%AE%BE%E8%AE%A1%E5%8E%9F%E5%88%99.html"}],["meta",{"property":"og:site_name","content":"薛志荣"}],["meta",{"property":"og:title","content":"语音交互-修复对话设计原则"}],["meta",{"property":"og:description","content":"cover_image 语音交互-修复对话设计原则 人和人之间的对话失败有两种可能，一是双方缺少共同的认知背景；二是对话不符合“合作原则”导致错误的表意，但是人会本能地、实时地互相纠正，使对话回到正确的轨道上。在人机对话过程中计算机会把以上两种失败和纠正过程都识别为错误，除此之外，人说话时的犹豫行为会导致语音识别的超时问题，环境噪音导致语音识别出其他内..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"en-US"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"语音交互-修复对话设计原则\\",\\"image\\":[\\"\\"],\\"dateModified\\":null,\\"author\\":[]}"]]},"headers":[],"git":{"updatedTime":null,"contributors":[]},"filePathRelative":"posts/blogs/HCI/20210315语音交互修复对话设计原则.md","autoDesc":true,"excerpt":"<p></p>\\n<h1>语音交互-修复对话设计原则</h1>\\n<p>人和人之间的对话失败有两种可能，一是双方缺少共同的认知背景；二是对话不符合“合作原则”导致错误的表意，但是人会本能地、实时地互相纠正，使对话回到正确的轨道上。在人机对话过程中计算机会把以上两种失败和纠正过程都识别为错误，除此之外，人说话时的犹豫行为会导致语音识别的超时问题，环境噪音导致语音识别出其他内容等因素会导致人机对话的失败。\\n对于机器编程产生的对话，设计师不要只将精力集中于所谓的“理想流程”和“预设逻辑”中。在对话过程中用户很难知道为什么出现了对话失败，更不可能知道在多层语音和语言识别系统复杂的结构中到底是哪里出现了错误。要使对话能够顺利进行，需要很多条件很好地结合在一起才能达成，包括语音信号处理、数据网络传输、自然语言理解等等，一旦一处地方不符合预期就会引发“出错”。所以设计师应该考虑并解决这些问题，例如设计相关的对白告知用户当前的状况是什么，提供修复错误的说明引导，使整个人机对话能够基于对话流和“合作原则”重回正轨。修复对话的关键在于学会站在机器视角来看待问题，以下4种常见情况会都会导致对话的失败：\\n1.机器没有获取到任何输入。可能是因为确实没有，也可能是系统没有检测到。结果就是造成系统获取信息超时。\\n2.虽然机器获取到了信息，但是却不能识别或解析，这种情况可能是因为背景噪音，或是有多个用户一起说话。\\n3.识别了用户的输入信息，但系统不知道如何去回应处理。例如用户可能会说：“我不知道怎么调整音量”，此时系统也许会错误地解析信息，无法正确的处理请求。\\n4.错误地识别了用户的输入信息，这种情况可能是最坏的一种结果。因为用户会被误导，而谈话会继续向错误的方向继续。\\n以上4种常见情况，我们总不能对用户说“我没听懂那句话”或是“抱歉我没理解”。一句“对不起”可能是最简单、最直接、成本最低的回复，但要避免过度使用。因为在大部分情况下都有比道歉更好的沟通方式，提供解决方案比道歉更有用。这时候我们可以考虑以下做法：\\n1.当用户超时输入或者无输入时，我们可以再次提示一遍用户刚才问的问题，这时可以用较为简洁的句式变体对原有问题进行二次询问，而不是每次都告诉用户“没有听到”或者“不明白”。\\n2.理解内容但不能提供帮助，这里分四种情况。第一种是智能助手不支持用户要求的功能时，我们可以使用说“我目前还不能帮助你做xx事”来告诉用户该功能不可用，但可能在将来支持。为了支持这点，我们需要提前计划要做的功能的意图。然后，我们可以跟踪用户何时请求不支持的功能，这能让我们更好的确定功能的优先级。例如用户想在订制旅程的技能中租车，如果不支持智能助手可以说：“我现在还不能帮你租车。但我可以帮你订制旅行，你想去哪个城市？”\\n第二种是用户说法不清导致意图识别信息缺失，这时候需要通过询问引导用户澄清一遍，完成必要槽位信息的补足。在询问过程中，建议列举相关内容供用户参考。例如用户需要打电话给朋友小王时，但小王有两个电话号码，这时候智能助手可以问：“小王有两个电话号码，请问你要打点给第一个还是第二个呢？”\\n第三种是由于阈值上下限的缘故，智能助手不能提供完整的帮助，这时候应该告诉用户当前状况并推荐相关操作。例如用户要调高空调的温度到100°C，或者想在30°C的基础上调高10°C，这时候智能助手可以说：“抱歉，当前空调最高温度为33°C，已经为你调到最高温度了。”\\n最后一种情况是明确知道用户的指令是错误的，需要引导用户重回正轨或者恢复默认状态。例如空调的吹风档位有1~4档，用户有可能太冷说了一句“关闭4档”。用户的潜意识是认为4档风量太大，他想把风量调低一点，但是用户不知道吹风档位意图识别上只有切换没有关闭的概念。所以我们应该提前想到用户的常用说法，并在意图设计和回复上体现出来，这时候智能助手可以回答：“吹风档位已经为你调回1档啦”。\\n3.由于各种原因导致识别不清晰，系统不知道用户说了什么。建议在兜底模块中首先通过关键字匹配和内容相似度的方式纠正指令，从而为用户解决问题。如果以上方法不可行，再对内容进行语法分析和关键字匹配，如果匹配上关键字可以交由FAQ模块或者第三方搜索模块来解决。如果没匹配上关键字，语法分析没太大问题可以交由闲聊模块解决，问题很大则告知用户“抱歉我没理解”（语句中语法有严重问题一般都是噪音导致）。\\n4.用户在多轮对话过程中没按剧本走导致理解出问题时，可以在多轮交互过程中提示用户目前所支持的说法是什么，限制用户的说法；或者询问用户是否退出当前多轮对话并进入新一轮对话中。\\n本章节的最后提供一份Google语音交互设计走查表，里面的内容包括问候语与结束语、对话的自然流畅、人物画像、对话修复/容错，它能为读者提供快速的检查方法，有效确保自己的设计是否合理。<br>\\n\\n\\n\\n<strong>文章最后</strong>\\n最近笔者会抽空把第二本书中和语音交互设计相关的内容陆续更新到公众号，后续还有最后一部分内容《语音交互的GUI设计》。如果读者对本节内容有任何建议或者疑问，请在后台留言:-)</p>"}');export{M as comp,w as data};
