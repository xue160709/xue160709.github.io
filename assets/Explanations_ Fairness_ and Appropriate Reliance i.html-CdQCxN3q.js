import{_ as r,r as n,o as l,c as o,a as e,b as t,d as i,e as s}from"./app-BLtyF54X.js";const p={},c=e("h1",{id:"解释、公平与适当依赖-人工智能辅助决策中的影响",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#解释、公平与适当依赖-人工智能辅助决策中的影响"},[e("span",null,"解释、公平与适当依赖：人工智能辅助决策中的影响")])],-1),h=e("div",{style:{position:"relative",width:"100%","padding-top":"56.25%"}},[e("iframe",{src:"https://www.youtube.com/embed/unz6iK4XnaY?si=SORYSz3gtNSsMCR8",style:{position:"absolute",top:"0",left:"0",width:"100%",height:"100%"},frameborder:"0",allow:"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share",referrerpolicy:"strict-origin-when-cross-origin",allowfullscreen:""})],-1),d=s('<h2 id="论文总结" tabindex="-1"><a class="header-anchor" href="#论文总结"><span>论文总结</span></a></h2><h3 id="研究机构" tabindex="-1"><a class="header-anchor" href="#研究机构"><span>研究机构</span></a></h3><p>The University of Texas at Austin, USA University of Bayreuth, Germany</p><h3 id="摘要" tabindex="-1"><a class="header-anchor" href="#摘要"><span>摘要</span></a></h3><p>本研究聚焦于人工智能（AI）辅助决策中，解释、公平性与适当依赖之间的关系。研究者Jakob Schoeffer, Maria De-Arteaga和Niklas Kühl通过一项基于 BIOS 数据集的实验，探索了不同类型的解释如何影响用户对AI推荐的接受度，以及这是否能促进分配公正。结果表明，解释可能会影响人们对AI决策公平性的感知，并且在选择依赖或不依赖AI推荐时有所作用。然而，对于任务相关特征的解释可降低错误率差异，而性别相关的解释则可能导致错误率差异增加。此外，人们的公平感知与他们是否纠正AI的误判有关，但并不一定意味着人们能更准确地区分正确和错误的AI建议。研究者提出，设计解释时应考虑提供对实现目标有帮助的相关提示，以促进分布公正，并指出当前流行的基于特征的解释方法可能不足以提升这一公正性。</p><h3 id="问题发现" tabindex="-1"><a class="header-anchor" href="#问题发现"><span>问题发现</span></a></h3><ul><li>AI辅助决策中的解释是否有助于提高公平性和适当依赖。</li><li>不同类型的解释（如关注任务相关或性别相关特征）如何影响用户行为。</li><li>用户对AI推荐的依赖程度与其对系统公平性的感知之间的关系。</li></ul><h3 id="解决方案" tabindex="-1"><a class="header-anchor" href="#解决方案"><span>解决方案</span></a></h3><ul><li>开展一项随机实验，比较了两种类型解释的影响：一种强调任务相关词汇，另一种强调可能与性别相关的词汇。</li><li>分析参与者在不同情况下的决策准确性、是否接受或反驳AI建议，以及他们对AI公平性的感知。</li><li>通过收集数据和分析，探索解释、公平感知和依赖行为之间的关系。</li></ul><h3 id="结果" tabindex="-1"><a class="header-anchor" href="#结果"><span>结果</span></a></h3><ul><li>提供了任务相关解释的条件下，人们的错误率差异较小，而性别相关解释可能导致错误率差异增加。</li><li>参与者在看到性别相关解释时更可能纠正AI的误判，但这种纠正行为并不一定减少整体错误或提高决策准确性。</li><li>公平感知和依赖行为之间存在负相关，即公平感知越低，参与者越倾向于反驳AI建议，但这并不意味着他们能更好地判断AI建议的正确性。</li></ul><h2 id="举一反三" tabindex="-1"><a class="header-anchor" href="#举一反三"><span>举一反三</span></a></h2><h4 id="q1-解释对决策准确性的影响是什么" tabindex="-1"><a class="header-anchor" href="#q1-解释对决策准确性的影响是什么"><span>Q1：解释对决策准确性的影响是什么？</span></a></h4><p>A1：根据研究，解释可以增强人们在欺骗检测任务中的决策准确性。然而，在我们的实验中，提供解释并未显著提高参与者的决策准确性。</p><h4 id="q2-公平感知如何与解释和依赖性相关联" tabindex="-1"><a class="header-anchor" href="#q2-公平感知如何与解释和依赖性相关联"><span>Q2：公平感知如何与解释和依赖性相关联？</span></a></h4><p>A2：参与者对AI决策过程的公平感知会影响他们是否以及多大程度上依赖AI建议。较高的公平感知与较少的依赖度有关，这表明人们在相信系统更公正时可能更少地遵循AI推荐。</p><h4 id="q3-性别化解释如何影响人们的决定" tabindex="-1"><a class="header-anchor" href="#q3-性别化解释如何影响人们的决定"><span>Q3：性别化解释如何影响人们的决定？</span></a></h4><p>A3：性别化解释可能会增加对女性的错误分类，并可能导致参与者更频繁地纠正和违背这些推荐。这可能是因为解释中的性别相关特征引发了关于公平的问题，进而影响了人们的决策行为。</p><hr><p><strong>信息来源</strong></p>',20),m={href:"https://dl.acm.org/doi/fullHtml/10.1145/3613904.3642621",target:"_blank",rel:"noopener noreferrer"},u={href:"https://www.mix-copilot.com/",target:"_blank",rel:"noopener noreferrer"};function _(f,g){const a=n("ExternalLinkIcon");return l(),o("div",null,[c,h,d,e("ul",null,[e("li",null,[e("a",m,[t("https://dl.acm.org/doi/fullHtml/10.1145/3613904.3642621"),i(a)])])]),e("p",null,[t("内容由"),e("a",u,[t("MiX Copilot"),i(a)]),t("基于大语言模型生成，有可能存在错误的风险。")])])}const y=r(p,[["render",_],["__file","Explanations_ Fairness_ and Appropriate Reliance i.html.vue"]]),I=JSON.parse('{"path":"/posts/papers/AI/Explanations_%20Fairness_%20and%20Appropriate%20Reliance%20i.html","title":"解释、公平与适当依赖：人工智能辅助决策中的影响","lang":"zh-CN","frontmatter":{"description":"研究表明，解释影响人们对AI决策的公平感知，并与他们是否依赖AI建议有关。然而，它们可能不论AI建议正确与否都影响依赖性。","date":"2024/5/23 21:06:12","head":[["meta",{"property":"og:url","content":"https://xuezhirong.com/posts/papers/AI/Explanations_%20Fairness_%20and%20Appropriate%20Reliance%20i.html"}],["meta",{"property":"og:site_name","content":"薛志荣的知识库"}],["meta",{"property":"og:title","content":"解释、公平与适当依赖：人工智能辅助决策中的影响"}],["meta",{"property":"og:description","content":"研究表明，解释影响人们对AI决策的公平感知，并与他们是否依赖AI建议有关。然而，它们可能不论AI建议正确与否都影响依赖性。"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"article:author","content":"薛志荣"}],["meta",{"property":"article:published_time","content":"2024-05-23T13:06:12.000Z"}],["meta",{"property":"og:updated_time","content":"2024-06-24T15:46:57.798Z"}],["meta",{"property":"og:modified_time","content":"2024-06-24T15:46:57.798Z"}],["meta",{"name":"twitter:title","content":"解释、公平与适当依赖：人工智能辅助决策中的影响"}],["meta",{"name":"twitter:description","content":"研究表明，解释影响人们对AI决策的公平感知，并与他们是否依赖AI建议有关。然而，它们可能不论AI建议正确与否都影响依赖性。"}],["meta",{"name":"twitter:card","content":"summary_large_image"}],["meta",{"name":"twitter:site","content":"@XueZhirong"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"解释、公平与适当依赖：人工智能辅助决策中的影响\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2024-05-23T13:06:12.000Z\\",\\"dateModified\\":null,\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"薛志荣\\"}]}"]]},"headers":[{"level":2,"title":"论文总结","slug":"论文总结","link":"#论文总结","children":[{"level":3,"title":"研究机构","slug":"研究机构","link":"#研究机构","children":[]},{"level":3,"title":"摘要","slug":"摘要","link":"#摘要","children":[]},{"level":3,"title":"问题发现","slug":"问题发现","link":"#问题发现","children":[]},{"level":3,"title":"解决方案","slug":"解决方案","link":"#解决方案","children":[]},{"level":3,"title":"结果","slug":"结果","link":"#结果","children":[]}]},{"level":2,"title":"举一反三","slug":"举一反三","link":"#举一反三","children":[]}],"git":{"updatedTime":null,"contributors":[]},"filePathRelative":"posts/papers/AI/Explanations, Fairness, and Appropriate Reliance i.md","excerpt":"\\n<div style=\\"position: relative; width: 100%; padding-top: 56.25%;\\"><iframe src=\\"https://www.youtube.com/embed/unz6iK4XnaY?si=SORYSz3gtNSsMCR8\\" style=\\"position: absolute; top: 0; left: 0; width: 100%; height: 100%;\\" frameborder=\\"0\\" allow=\\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\\" referrerpolicy=\\"strict-origin-when-cross-origin\\" allowfullscreen=\\"\\"></iframe></div>"}');export{y as comp,I as data};
