import{_ as i,r,o as s,c as l,a as t,b as e,d as n,e as o}from"./app-BcNaay3g.js";const p="/assets/Pasted%20image%2020240516122520-61XWiXVF.png",h="/assets/Pasted%20image%2020240516122530-tUwVnUOw.png",c={},d=o('<h1 id="使用大型语言模型协助从头开始编写类似维基百科的文章" tabindex="-1"><a class="header-anchor" href="#使用大型语言模型协助从头开始编写类似维基百科的文章"><span>使用大型语言模型协助从头开始编写类似维基百科的文章</span></a></h1><h2 id="论文总结" tabindex="-1"><a class="header-anchor" href="#论文总结"><span>论文总结</span></a></h2><h3 id="研究机构" tabindex="-1"><a class="header-anchor" href="#研究机构"><span>研究机构</span></a></h3><ul><li>斯坦福大学（Stanford University）</li></ul><h3 id="摘要" tabindex="-1"><a class="header-anchor" href="#摘要"><span>摘要</span></a></h3><p>本研究关注如何利用大型语言模型（LLMs）从头开始撰写具有广度和深度的维基百科风格的文章。这一尚未充分探索的问题在写作前阶段提出了新的挑战，包括如何研究主题并准备大纲，以便有组织地进行写作。研究者提出了一种名为STORM的方法，它通过模拟对话中的多视角问题来研究主题，并使用特定视角来引导提问。STORM通过创建可以逐节扩展至全文的大纲来生成完整的维基百科式文章。</p><p><img src="'+p+'" alt=""></p><p><img src="'+h+'" alt=""></p><h3 id="问题发现" tabindex="-1"><a class="header-anchor" href="#问题发现"><span>问题发现</span></a></h3><ul><li>如何有效利用LLMs在没有明确大纲或参考文档的情况下撰写长篇内容。</li><li>在写作前阶段（如收集和整理相关信息）的挑战，包括研究、准备大纲以及保持内容的权威性和连贯性。</li></ul><h3 id="解决方案" tabindex="-1"><a class="header-anchor" href="#解决方案"><span>解决方案</span></a></h3><ul><li>STORM采用多阶段方法：首先通过检索相似主题的维基百科文章来发现不同的视角，并使用这些视角控制提问过程。</li><li>通过模拟专家与模型对话，模型能更新对主题的理解并提出更深入的问题。</li><li>利用LLMs生成可信来源的答案，以回答在查询过程中提出的问题。</li></ul><h3 id="结果" tabindex="-1"><a class="header-anchor" href="#结果"><span>结果</span></a></h3><ul><li>经过自动和人类评估，STORM方法在大纲质量方面优于基于大纲的检索增强生成（RAG）基线。</li><li>通过与 Wikipedia 编辑的人工评价，STORM展现出其生成的文章具有较高的连贯性、相关性和可验证性。</li><li>编辑反馈显示，STORM生成的文章比基线提供了更多背景信息，并且深度更佳。</li></ul><h3 id="结论" tabindex="-1"><a class="header-anchor" href="#结论"><span>结论</span></a></h3><p>STORM通过自动化预写作阶段，利用LLMs有效研究主题并创建全面的大纲，为撰写维基百科风格文章提供了一种可行的方法。该方法在某些方面超越了现有的基于检索的生成模型，并为未来长篇内容生成提供了新的思路。</p><h2 id="举一反三" tabindex="-1"><a class="header-anchor" href="#举一反三"><span>举一反三</span></a></h2><h4 id="q1-storm在撰写文章时如何处理信息的多样性和来源" tabindex="-1"><a class="header-anchor" href="#q1-storm在撰写文章时如何处理信息的多样性和来源"><span>Q1：STORM在撰写文章时如何处理信息的多样性和来源？</span></a></h4><p>A1：STORM通过发现不同视角，例如通过检索类似主题的维基百科文章，并使用这些视角控制提问过程。它模拟与专家的对话以获取更深入的问题答案，并利用可信赖的互联网资源作为基础来生成内容。</p><h4 id="q2-如何评估storm在撰写文章时的预写阶段" tabindex="-1"><a class="header-anchor" href="#q2-如何评估storm在撰写文章时的预写阶段"><span>Q2：如何评估STORM在撰写文章时的预写阶段？</span></a></h4><p>A2：STORM的预写阶段通过创建能够扩展为多级标题列表的轮廓来进行评估。使用软标题召回率和实体头文件回忆率来衡量其相对于人类写作的全面性。此外，还邀请了经验丰富的维基百科编辑进行专家评价。</p><h4 id="q3-如何解决storm在生成文章时可能存在的问题-比如偏见转移和信息准确性" tabindex="-1"><a class="header-anchor" href="#q3-如何解决storm在生成文章时可能存在的问题-比如偏见转移和信息准确性"><span>Q3：如何解决STORM在生成文章时可能存在的问题，比如偏见转移和信息准确性？</span></a></h4><p>A3：为了解决这些问题，可以继续改进模型训练数据的质量，确保使用中立且可靠的来源。同时，对模型生成的内容进行人工审核和校正，以减少错误和不准确的信息，并避免偏见的传递。</p><hr>',24),m={href:"https://arxiv.org/html/2402.14207v2",target:"_blank",rel:"noopener noreferrer"},g={href:"https://www.mix-copilot.com/",target:"_blank",rel:"noopener noreferrer"};function u(_,f){const a=r("ExternalLinkIcon");return s(),l("div",null,[d,t("p",null,[e("原文地址："),t("a",m,[e("https://arxiv.org/html/2402.14207v2"),n(a)])]),t("p",null,[e("内容由"),t("a",g,[e("MiX Copilot"),n(a)]),e("基于大语言模型生成，有可能存在错误的风险。")])])}const M=i(c,[["render",u],["__file","Assisting in Writing Wikipedia.html.vue"]]),k=JSON.parse('{"path":"/posts/papers/AI/Assisting%20in%20Writing%20Wikipedia.html","title":"使用大型语言模型协助从头开始编写类似维基百科的文章","lang":"zh-CN","frontmatter":{"description":"本研究旨在利用大型语言模型自动生成具有广度和深度的维基百科文章，解决从头开始编写长篇内容的挑战。","date":"2024/5/16 12:23:11","head":[["meta",{"property":"og:url","content":"https://xuezhirong.com/posts/papers/AI/Assisting%20in%20Writing%20Wikipedia.html"}],["meta",{"property":"og:site_name","content":"薛志荣的知识库"}],["meta",{"property":"og:title","content":"使用大型语言模型协助从头开始编写类似维基百科的文章"}],["meta",{"property":"og:description","content":"本研究旨在利用大型语言模型自动生成具有广度和深度的维基百科文章，解决从头开始编写长篇内容的挑战。"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"article:author","content":"薛志荣"}],["meta",{"property":"article:published_time","content":"2024-05-16T04:23:11.000Z"}],["meta",{"property":"og:updated_time","content":"2024-06-09T02:16:47.202Z"}],["meta",{"property":"og:modified_time","content":"2024-06-09T02:16:47.202Z"}],["meta",{"name":"twitter:title","content":"使用大型语言模型协助从头开始编写类似维基百科的文章"}],["meta",{"name":"twitter:description","content":"本研究旨在利用大型语言模型自动生成具有广度和深度的维基百科文章，解决从头开始编写长篇内容的挑战。"}],["meta",{"name":"twitter:card","content":"summary_large_image"}],["meta",{"name":"twitter:site","content":"@XueZhirong"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"使用大型语言模型协助从头开始编写类似维基百科的文章\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2024-05-16T04:23:11.000Z\\",\\"dateModified\\":null,\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"薛志荣\\"}]}"]]},"headers":[{"level":2,"title":"论文总结","slug":"论文总结","link":"#论文总结","children":[{"level":3,"title":"研究机构","slug":"研究机构","link":"#研究机构","children":[]},{"level":3,"title":"摘要","slug":"摘要","link":"#摘要","children":[]},{"level":3,"title":"问题发现","slug":"问题发现","link":"#问题发现","children":[]},{"level":3,"title":"解决方案","slug":"解决方案","link":"#解决方案","children":[]},{"level":3,"title":"结果","slug":"结果","link":"#结果","children":[]},{"level":3,"title":"结论","slug":"结论","link":"#结论","children":[]}]},{"level":2,"title":"举一反三","slug":"举一反三","link":"#举一反三","children":[]}],"git":{"updatedTime":null,"contributors":[]},"filePathRelative":"posts/papers/AI/Assisting in Writing Wikipedia.md","excerpt":"\\n<h2>论文总结</h2>\\n<h3>研究机构</h3>\\n<ul>\\n<li>斯坦福大学（Stanford University）</li>\\n</ul>\\n<h3>摘要</h3>\\n<p>本研究关注如何利用大型语言模型（LLMs）从头开始撰写具有广度和深度的维基百科风格的文章。这一尚未充分探索的问题在写作前阶段提出了新的挑战，包括如何研究主题并准备大纲，以便有组织地进行写作。研究者提出了一种名为STORM的方法，它通过模拟对话中的多视角问题来研究主题，并使用特定视角来引导提问。STORM通过创建可以逐节扩展至全文的大纲来生成完整的维基百科式文章。</p>\\n<p></p>\\n<p></p>\\n<h3>问题发现</h3>"}');export{M as comp,k as data};
