import{_ as a,c as i,o as n,a as e,b as t}from"./app-UZPMjXWD.js";const l={},r=e("h1",{id:"你应该害怕人工智能吗-yann-lecun-和人工智能专家讨论我们应该如何控制人工智能-youtube",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#你应该害怕人工智能吗-yann-lecun-和人工智能专家讨论我们应该如何控制人工智能-youtube"},[e("span",null,"你应该害怕人工智能吗？：Yann LeCun 和人工智能专家讨论我们应该如何控制人工智能 - YouTube")])],-1),s=e("div",{style:{position:"relative",width:"100%","padding-top":"56.25%"}},[e("iframe",{src:"https://www.youtube.com/embed/Wb_kOiid-vc",style:{position:"absolute",top:"0",left:"0",width:"100%",height:"100%"},frameborder:"0",allow:"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share",referrerpolicy:"strict-origin-when-cross-origin",allowfullscreen:""})],-1),o=t('<h2 id="_1-视频核心内容" tabindex="-1"><a class="header-anchor" href="#_1-视频核心内容"><span>1. 视频核心内容</span></a></h2><p>在达沃斯论坛上，Yann LeCun和其他人工智能（AI）专家讨论了AI的潜在限制、我们应该如何控制AI，以及未来AI技术的发展方向。他们探讨了如何使AI成为一种工具，既能产生积极影响，又能避免负面后果。尽管专家们对AI潜在风险的看法有所不同，但他们一致认为AI应当被设计成我们可以控制的工具，以补充和帮助人类。</p><h2 id="_2-主要讨论点" tabindex="-1"><a class="header-anchor" href="#_2-主要讨论点"><span>2. 主要讨论点</span></a></h2><h3 id="_2-1-开放源代码ai的争议" tabindex="-1"><a class="header-anchor" href="#_2-1-开放源代码ai的争议"><span>2.1 开放源代码AI的争议</span></a></h3><p>一些观点认为开放源代码的AI应当被禁止，因为它威胁到了垄断性科技公司的利益。与此同时，有人认为大学应该停止AI研究，因为公司在这方面做得更好。还有观点认为AI安全问题不重要，应当把注意力转向量子计算。</p><h3 id="_2-2-ai的当前挑战" tabindex="-1"><a class="header-anchor" href="#_2-2-ai的当前挑战"><span>2.2 AI的当前挑战</span></a></h3><p>当前AI面临许多挑战，其中深度伪造（Deep Fakes）在选举和欺诈中尤为重要。专家们强调，我们应当关注未来AI的发展，而不仅仅是当前的问题。</p><h3 id="_2-3-人工通用智能-agi" tabindex="-1"><a class="header-anchor" href="#_2-3-人工通用智能-agi"><span>2.3 人工通用智能（AGI）</span></a></h3><p>AGI，即能够执行所有人类认知任务的AI，尚不存在。专家们普遍认为，我们可能在未来100年内实现AGI，但实现这一目标的时间可能会更长。因此，如何确保AI成为一种可控的工具，是一个重要问题。</p><h3 id="_2-4-ai的经济驱动力" tabindex="-1"><a class="header-anchor" href="#_2-4-ai的经济驱动力"><span>2.4 AI的经济驱动力</span></a></h3><p>即使专家们认为可以暂缓发展超智能AI，但经济驱动力可能会推动这一进程。AGI的潜在价值可能高达15千万亿美元，这使得禁止其发展的建议难以实施。</p><h3 id="_2-5-ai与人类智能的比较" tabindex="-1"><a class="header-anchor" href="#_2-5-ai与人类智能的比较"><span>2.5 AI与人类智能的比较</span></a></h3><p>人类智能是高度专业化的，我们当前的AI系统尚未达到这一水平。专家们认为，未来AI系统需要具备与人类和动物类似的学习效率，以便在日常生活中更好地帮助我们。</p><h3 id="_2-6-对技术进步的控制" tabindex="-1"><a class="header-anchor" href="#_2-6-对技术进步的控制"><span>2.6 对技术进步的控制</span></a></h3><p>尽管技术进步不可避免，但我们应当寻找方法确保这些技术被用于积极目的。历史上有许多技术在原型阶段被发现过于危险而未被广泛应用，如核动力汽车和核动力飞船。</p><h3 id="_2-7-未来ai系统的架构" tabindex="-1"><a class="header-anchor" href="#_2-7-未来ai系统的架构"><span>2.7 未来AI系统的架构</span></a></h3><p>未来的AI系统需要具备目标导向和安全机制，以防止被黑客攻击或出现其他安全问题。这些系统应当能够计划、推理、记忆，并理解物理世界。</p><h3 id="_2-8-社会技术的重要性" tabindex="-1"><a class="header-anchor" href="#_2-8-社会技术的重要性"><span>2.8 社会技术的重要性</span></a></h3><p>在解决AI问题时，社会技术与技术本身同样重要。技术乐观主义不能替代人文主义，必须同时考虑技术和社会因素。</p><h2 id="_3-专家观点总结" tabindex="-1"><a class="header-anchor" href="#_3-专家观点总结"><span>3. 专家观点总结</span></a></h2><p>尽管在具体细节上存在分歧，但专家们一致认为，AI应当被设计成我们可以控制的工具，以补充和帮助人类。他们提出了各种技术和社会解决方案，以确保AI的发展方向符合人类的整体利益。</p><h2 id="_4-未来展望" tabindex="-1"><a class="header-anchor" href="#_4-未来展望"><span>4. 未来展望</span></a></h2><p>未来的AI系统将更加复杂和智能，但我们需要确保这些系统的安全性和可控性。通过结合机器学习、控制理论和其他技术手段，我们可以开发出更安全、更有效的AI系统。同时，社会技术的发展也至关重要，以确保技术进步带来的好处能够惠及全人类。</p><h2 id="_5-结论" tabindex="-1"><a class="header-anchor" href="#_5-结论"><span>5. 结论</span></a></h2><p>AI的未来充满了机遇和挑战。通过合理的技术和社会措施，我们可以确保AI成为一种有益的工具，为人类社会带来积极影响。专家们的讨论为我们提供了宝贵的见解，帮助我们更好地理解和应对AI的未来发展。</p><h2 id="_2-作者核心观点" tabindex="-1"><a class="header-anchor" href="#_2-作者核心观点"><span>2.作者核心观点</span></a></h2><ol><li><p><strong>对AI的恐惧与控制</strong></p><ul><li>讨论了生成型AI的潜在限制、AI未来的变革性进展以及“生成型AI”的含义。</li><li>强调不应过度担忧AI，而应专注于如何有效地控制和利用AI。</li></ul></li><li><p><strong>AI的潜力与挑战</strong></p><ul><li>目前AI面临许多挑战，如深度伪造（deep fakes）在选举和欺诈中的应用。</li><li>AI的最终目标是解决智能问题，使机器能够执行人类能做的一切任务，甚至更好。</li></ul></li><li><p><strong>人工通用智能（AGI）</strong></p><ul><li>讨论了何时能实现AGI的可能性。</li><li>大多数专家认为我们尚未达到AGI，但在未来100年内可能会实现。</li></ul></li><li><p><strong>AI的经济驱动力</strong></p><ul><li>AGI可能带来的经济价值巨大，可能高达15万亿（quadrillion）美元。</li></ul></li><li><p><strong>AI的控制与安全</strong></p><ul><li>强调AI系统需要内置控制机制，确保其行为符合人类设定的目标。</li><li>讨论了如何在开发AI的同时确保其安全性，避免其对人类造成威胁。</li></ul></li><li><p><strong>技术与社会的结合</strong></p><ul><li>强调技术解决方案需要结合社会技术，不能忽视社会因素。</li><li>需要通过社会和技术的结合来解决AI带来的复杂问题。</li></ul></li><li><p><strong>未来的AI架构</strong></p><ul><li>讨论了未来可能的AI架构，如目标驱动系统、液态网络和结合控制理论的机器学习工具。</li><li>强调这些新架构将更安全、更可控。</li></ul></li></ol><p>总的来说，作者认为虽然AI带来了许多挑战，但通过适当的控制和技术发展，我们可以充分利用AI的潜力，同时确保其安全性和可控性。</p><h2 id="_3-专业知识" tabindex="-1"><a class="header-anchor" href="#_3-专业知识"><span>3.专业知识</span></a></h2><h3 id="人工智能-ai-与agi" tabindex="-1"><a class="header-anchor" href="#人工智能-ai-与agi"><span>人工智能（AI）与AGI</span></a></h3><ul><li><strong>人工智能的目标</strong>：从一开始，AI的最终目标就是解决智能问题，制造出能够完成所有人类任务的机器，并且最好能比人类做得更好。</li><li><strong>人工智能与人类智能的差异</strong>：目前的AI系统还没有达到人类或动物的智能水平，特别是学习效率方面。</li><li><strong>人工通用智能（AGI）</strong>：目前还不存在AGI，AGI指的是能够完成所有人类认知任务的AI系统。</li></ul><h3 id="ai的挑战与风险" tabindex="-1"><a class="header-anchor" href="#ai的挑战与风险"><span>AI的挑战与风险</span></a></h3><ul><li><strong>深度伪造（Deep Fake）</strong>：在选举和欺诈等方面，深度伪造技术带来了许多挑战。</li><li><strong>经济驱动因素</strong>：如果AGI的经济价值被估计为15千万亿美元，阻止其发展的难度会非常大。</li><li><strong>技术与社会问题</strong>：AI技术的进步不仅是技术问题，也是社会问题，需要考虑技术的社会影响。</li></ul><h3 id="ai的控制与安全" tabindex="-1"><a class="header-anchor" href="#ai的控制与安全"><span>AI的控制与安全</span></a></h3><ul><li><strong>目标驱动的AI系统</strong>：未来的AI系统应该是目标驱动的，在推理时必须满足一系列的约束条件，以确保系统的安全性和可控性。</li><li><strong>社会技术的重要性</strong>：解决AI问题不仅需要技术，还需要社会技术，忽视社会问题将导致失败。</li><li><strong>技术与社会的结合</strong>：结合机器学习与控制理论的工具，如障碍网络（Barrier Net）和控制障碍函数，以确保机器学习系统的输出是安全的。</li></ul><h3 id="ai的应用与未来" tabindex="-1"><a class="header-anchor" href="#ai的应用与未来"><span>AI的应用与未来</span></a></h3><ul><li><strong>医疗突破</strong>：AI在医疗领域可以带来重大突破。</li><li><strong>消除贫困</strong>：AI有潜力帮助消除贫困。</li><li><strong>气候变化</strong>：AI技术可以用于应对气候变化。</li><li><strong>商业机会</strong>：AI可以创造新的商业机会，不需要达到AGI水平。</li></ul><h3 id="ai的伦理与发展" tabindex="-1"><a class="header-anchor" href="#ai的伦理与发展"><span>AI的伦理与发展</span></a></h3><ul><li><strong>科学与知识的边界</strong>：科学的发展不应被限制，但需要找到确保发明用于善而非恶的机制。</li><li><strong>技术的双面性</strong>：每项技术都有正面和负面影响，需通过技术和社会机制来确保其正面应用。</li><li><strong>技术蓝图与控制</strong>：未来的智能系统需要具备内在的控制机制，研究应致力于开发安全且可控的技术。</li></ul><p>这些专业知识展示了当前AI技术的发展方向、面临的挑战和潜在的解决方案，强调了技术与社会的结合对于确保AI安全和可控的重要性。</p><h2 id="_4-举一反三" tabindex="-1"><a class="header-anchor" href="#_4-举一反三"><span>4.举一反三</span></a></h2><h4 id="_1-人工智能是否会在未来几年内显著改进" tabindex="-1"><a class="header-anchor" href="#_1-人工智能是否会在未来几年内显著改进"><span>1. 人工智能是否会在未来几年内显著改进？</span></a></h4><p>是的，所有的专家都认为人工智能在未来几年内会有显著改进。每位专家都同意，尽管目前的人工智能还没有达到人类水平，但它们将继续进步，并在许多领域提供重要帮助。</p><h4 id="_2-我们是否应该限制超级智能的发展" tabindex="-1"><a class="header-anchor" href="#_2-我们是否应该限制超级智能的发展"><span>2. 我们是否应该限制超级智能的发展？</span></a></h4><p>专家们对此问题存在不同看法。部分专家认为，应该推迟超级智能的发展，直到我们能够确保其安全性，而另一些专家则认为，经济驱动力和科学进步将不可避免地推动超级智能的发展。总体而言，所有专家都同意，我们需要找到一种方法来控制人工智能，以获得其好处而避免潜在的风险。</p><h4 id="_3-我们如何确保人工智能的安全性" tabindex="-1"><a class="header-anchor" href="#_3-我们如何确保人工智能的安全性"><span>3. 我们如何确保人工智能的安全性？</span></a></h4><p>专家们提出了多种方法来确保人工智能的安全性。一些专家建议开发新的系统架构，这些架构在推理时需要满足一系列保护措施。另一些专家则强调，除了技术解决方案外，还需要社会技术的支持，确保在开发和部署人工智能时考虑到社会和政治因素。总体而言，控制和安全性是每个专家都非常重视的问题。</p><hr><p><strong>信息来源</strong></p><ul><li><a href="https://www.youtube.com/watch?v=Wb_kOiid-vc" target="_blank" rel="noopener noreferrer">https://www.youtube.com/watch?v=Wb_kOiid-vc</a></li></ul><p>内容由<a href="https://www.mix-copilot.com/" target="_blank" rel="noopener noreferrer">MiX Copilot</a>基于大语言模型生成，有可能存在错误的风险。</p>',51),h=[r,s,o];function p(d,c){return n(),i("div",null,h)}const u=a(l,[["render",p],["__file","Should You Be Afraid Of AI Yann LeCun And AI Exper.html.vue"]]),_=JSON.parse('{"path":"/posts/interviews/people/%E6%9D%A8%E7%AB%8B%E6%98%86/Should%20You%20Be%20Afraid%20Of%20AI%20Yann%20LeCun%20And%20AI%20Exper.html","title":"你应该害怕人工智能吗？：Yann LeCun 和人工智能专家讨论我们应该如何控制人工智能 - YouTube","lang":"en-US","frontmatter":{"description":"在达沃斯的对话中，专家讨论了生成型AI的潜在限制、未来发展以及如何控制AI的关键问题。","date":"2024/5/29 10:27:47","head":[["meta",{"property":"og:url","content":"https://xuezhirong.com/posts/interviews/people/%E6%9D%A8%E7%AB%8B%E6%98%86/Should%20You%20Be%20Afraid%20Of%20AI%20Yann%20LeCun%20And%20AI%20Exper.html"}],["meta",{"property":"og:site_name","content":"薛志荣的知识库"}],["meta",{"property":"og:title","content":"你应该害怕人工智能吗？：Yann LeCun 和人工智能专家讨论我们应该如何控制人工智能 - YouTube"}],["meta",{"property":"og:description","content":"在达沃斯的对话中，专家讨论了生成型AI的潜在限制、未来发展以及如何控制AI的关键问题。"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"en-US"}],["meta",{"property":"article:author","content":"薛志荣"}],["meta",{"property":"article:published_time","content":"2024-05-29T02:27:47.000Z"}],["meta",{"property":"og:updated_time","content":"2024-06-29T08:35:42.476Z"}],["meta",{"property":"og:modified_time","content":"2024-06-29T08:35:42.476Z"}],["meta",{"name":"twitter:title","content":"你应该害怕人工智能吗？：Yann LeCun 和人工智能专家讨论我们应该如何控制人工智能 - YouTube"}],["meta",{"name":"twitter:description","content":"在达沃斯的对话中，专家讨论了生成型AI的潜在限制、未来发展以及如何控制AI的关键问题。"}],["meta",{"name":"twitter:card","content":"summary_large_image"}],["meta",{"name":"twitter:site","content":"XueZhirong"}],["meta",{"name":"twitter:creator","content":"XueZhirong"}],["meta",{"name":"share_config","content":"twitter,weibo,facebook,email"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"你应该害怕人工智能吗？：Yann LeCun 和人工智能专家讨论我们应该如何控制人工智能 - YouTube\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2024-05-29T02:27:47.000Z\\",\\"dateModified\\":null,\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"薛志荣\\"}]}"]]},"headers":[{"level":2,"title":"1. 视频核心内容","slug":"_1-视频核心内容","link":"#_1-视频核心内容","children":[]},{"level":2,"title":"2. 主要讨论点","slug":"_2-主要讨论点","link":"#_2-主要讨论点","children":[{"level":3,"title":"2.1 开放源代码AI的争议","slug":"_2-1-开放源代码ai的争议","link":"#_2-1-开放源代码ai的争议","children":[]},{"level":3,"title":"2.2 AI的当前挑战","slug":"_2-2-ai的当前挑战","link":"#_2-2-ai的当前挑战","children":[]},{"level":3,"title":"2.3 人工通用智能（AGI）","slug":"_2-3-人工通用智能-agi","link":"#_2-3-人工通用智能-agi","children":[]},{"level":3,"title":"2.4 AI的经济驱动力","slug":"_2-4-ai的经济驱动力","link":"#_2-4-ai的经济驱动力","children":[]},{"level":3,"title":"2.5 AI与人类智能的比较","slug":"_2-5-ai与人类智能的比较","link":"#_2-5-ai与人类智能的比较","children":[]},{"level":3,"title":"2.6 对技术进步的控制","slug":"_2-6-对技术进步的控制","link":"#_2-6-对技术进步的控制","children":[]},{"level":3,"title":"2.7 未来AI系统的架构","slug":"_2-7-未来ai系统的架构","link":"#_2-7-未来ai系统的架构","children":[]},{"level":3,"title":"2.8 社会技术的重要性","slug":"_2-8-社会技术的重要性","link":"#_2-8-社会技术的重要性","children":[]}]},{"level":2,"title":"3. 专家观点总结","slug":"_3-专家观点总结","link":"#_3-专家观点总结","children":[]},{"level":2,"title":"4. 未来展望","slug":"_4-未来展望","link":"#_4-未来展望","children":[]},{"level":2,"title":"5. 结论","slug":"_5-结论","link":"#_5-结论","children":[]},{"level":2,"title":"2.作者核心观点","slug":"_2-作者核心观点","link":"#_2-作者核心观点","children":[]},{"level":2,"title":"3.专业知识","slug":"_3-专业知识","link":"#_3-专业知识","children":[{"level":3,"title":"人工智能（AI）与AGI","slug":"人工智能-ai-与agi","link":"#人工智能-ai-与agi","children":[]},{"level":3,"title":"AI的挑战与风险","slug":"ai的挑战与风险","link":"#ai的挑战与风险","children":[]},{"level":3,"title":"AI的控制与安全","slug":"ai的控制与安全","link":"#ai的控制与安全","children":[]},{"level":3,"title":"AI的应用与未来","slug":"ai的应用与未来","link":"#ai的应用与未来","children":[]},{"level":3,"title":"AI的伦理与发展","slug":"ai的伦理与发展","link":"#ai的伦理与发展","children":[]}]},{"level":2,"title":"4.举一反三","slug":"_4-举一反三","link":"#_4-举一反三","children":[]}],"git":{"updatedTime":null,"contributors":[]},"filePathRelative":"posts/interviews/people/杨立昆/Should You Be Afraid Of AI Yann LeCun And AI Exper.md","excerpt":"\\n<div style=\\"position: relative; width: 100%; padding-top: 56.25%;\\"><iframe src=\\"https://www.youtube.com/embed/Wb_kOiid-vc\\" style=\\"position: absolute; top: 0; left: 0; width: 100%; height: 100%;\\" frameborder=\\"0\\" allow=\\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\\" referrerpolicy=\\"strict-origin-when-cross-origin\\" allowfullscreen=\\"\\"></iframe></div>"}');export{u as comp,_ as data};
