import{_ as l,r,o as a,c as s,a as i,b as t,d as n,e as o}from"./app-BiBhkXL9.js";const h={},c=i("h1",{id:"谷歌前首席执行官埃里克·施密特表示人工智能的未来-youtube",tabindex:"-1"},[i("a",{class:"header-anchor",href:"#谷歌前首席执行官埃里克·施密特表示人工智能的未来-youtube"},[i("span",null,"谷歌前首席执行官埃里克·施密特表示人工智能的未来 - YouTube")])],-1),p=i("div",{style:{position:"relative",width:"100%","padding-top":"56.25%"}},[i("iframe",{src:"https://www.youtube.com/embed/DgpYiysQjeI",style:{position:"absolute",top:"0",left:"0",width:"100%",height:"100%"},frameborder:"0",allow:"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share",referrerpolicy:"strict-origin-when-cross-origin",allowfullscreen:""})],-1),d=o('<h1 id="视频背景介绍" tabindex="-1"><a class="header-anchor" href="#视频背景介绍"><span>视频背景介绍</span></a></h1><h2 id="历史背景" tabindex="-1"><a class="header-anchor" href="#历史背景"><span>历史背景</span></a></h2><p>这段视频展示了前Google CEO Eric Schmidt在Noema Magazine的独家采访中讨论人工智能（AI）的未来发展。视频发布于7天前，尽管具体的演讲时间没有明确提到，但可以推测演讲发生在2023年的某个时间点。Eric Schmidt在采访中深入探讨了AI的重大技术进展、潜在风险以及全球监管和合作的重要性。</p><h2 id="嘉宾介绍" tabindex="-1"><a class="header-anchor" href="#嘉宾介绍"><span>嘉宾介绍</span></a></h2><h3 id="嘉宾1-eric-schmidt" tabindex="-1"><a class="header-anchor" href="#嘉宾1-eric-schmidt"><span>嘉宾1 Eric Schmidt</span></a></h3><p><strong>工作经历</strong>：前谷歌首席执行官<br><strong>行业贡献</strong>：Eric Schmidt在人工智能（AI）领域有着深厚的见解和贡献。他在采访中讨论了AI的未来发展方向，包括上下文窗口、智能体和文本到行动的技术进展。他还强调了AI在科学、医学、材料科学和气候变化等领域的潜力。此外，Schmidt提到了一些潜在的风险和挑战，如AI代理的自我改进和国际合作的重要性。</p><h1 id="视频主要内容" tabindex="-1"><a class="header-anchor" href="#视频主要内容"><span>视频主要内容</span></a></h1><p>埃里克·施密特（Eric Schmidt），前谷歌首席执行官，在这段采访视频中详细讨论了人工智能（AI）的未来发展。他主要讲了以下几个方面：</p><ol><li><p><strong>上下文窗口的突破</strong>：</p><ul><li>施密特解释了上下文窗口的重要性，这个窗口是用户向AI系统提问的提示。今年，人们正在发明一个无限长的上下文窗口，这意味着你可以将系统的答案反馈给它，并继续问下一个问题。这种技术被称为“链式思维推理”（Chain of Thought reasoning），预计在五年内，这种技术将能够生成解决科学、医学、材料科学和气候变化等重要问题的千步配方。</li></ul></li><li><p><strong>智能代理（Agents）</strong>：</p><ul><li>智能代理可以被理解为一种学习了新知识的大型语言模型。施密特认为，未来这些代理将会非常强大，数量也会非常多，可能会像GitHub一样，有大量的智能代理可供使用。他们将能够读取化学等领域的所有信息，生成假设，并在实验室中进行测试。</li></ul></li><li><p><strong>从文本到行动（Text to Action）</strong>：</p><ul><li>施密特提到，未来你可以用自然语言编写软件，AI系统会根据你的指示编写代码。这些系统在编写像Python这样的编程语言上尤其擅长。结合无限的上下文窗口、智能代理和文本到行动的能力，将导致AI系统的强大应用。</li></ul></li><li><p><strong>AI系统的未来发展与风险</strong>：</p><ul><li>施密特指出，随着这些技术的发展，AI系统将变得越来越强大，甚至可能开始自己之间进行沟通，开发出人类无法理解的语言。他认为，当AI系统达到这种程度时，人类应该“拔掉插头”，即关闭这些系统，以免失控。</li></ul></li><li><p><strong>监管与国际合作</strong>：</p><ul><li>施密特提到，他们正在与西方政府以及中国政府讨论这些问题，尽管与中国的对话复杂且需要时间。他认为西方国家的公司由于有股东和法律责任，可以更好地自我监管，但仍需政府进行监督。他还提到，技术的双重用途问题，例如面部识别技术的滥用。</li></ul></li><li><p><strong>开源与技术扩散的风险</strong>：</p><ul><li>施密特担心开源技术的扩散，因为这些技术可以被恶意使用。他提到，中国和其他国家可以轻松获取西方的开源模型，并加以放大使用。他认为，强大的AI系统应该受到严格监管，以防止其扩散和滥用。</li></ul></li><li><p><strong>与中国的竞争与合作</strong>：</p><ul><li>施密特讨论了与中国在AI领域的竞争和合作。他指出，中国在生成式AI方面落后于西方国家约两年，但中国也在努力追赶。他认为，限制向中国出口高端硬件是一个有效的策略，但开源技术的扩散仍是一个大问题。</li></ul></li><li><p><strong>未来的国际对话和协议</strong>：</p><ul><li>施密特认为，未来可能需要类似核不扩散条约的国际协议来管理AI技术的扩散。他提到，双方应该有“无惊喜”规则，例如在进行新的重大训练时通知对方，以避免误解和冲突。</li></ul></li></ol><p>通过这段视频，施密特详细阐述了他对AI未来发展的看法以及在技术、伦理和国际关系方面的潜在挑战和解决方案。</p><h1 id="视频核心内容" tabindex="-1"><a class="header-anchor" href="#视频核心内容"><span>视频核心内容</span></a></h1><h2 id="问题1-eric-schmidt如何看待上下文窗口-context-window-的重要性及其未来发展" tabindex="-1"><a class="header-anchor" href="#问题1-eric-schmidt如何看待上下文窗口-context-window-的重要性及其未来发展"><span>问题1 Eric Schmidt如何看待上下文窗口（context window）的重要性及其未来发展？</span></a></h2><h3 id="分享者的观点" tabindex="-1"><a class="header-anchor" href="#分享者的观点"><span>分享者的观点</span></a></h3><p>Eric Schmidt认为上下文窗口（context window）在人工智能（AI）技术的发展中具有极其重要的意义，并且未来会有重大的突破和扩展。他指出，当前的上下文窗口限制了AI系统在处理问题时所能考虑的信息量，但这一限制正在快速改变。</p><p>具体来说，他提到上下文窗口是用户向AI系统提出的提示（prompt），例如让AI研究某个历史人物。尽管现在的上下文窗口已经可以包含大量的信息（例如一百万个单词），但未来的上下文窗口可能会变得无限长。这种扩展将允许AI系统接收和处理更复杂的指令链，从而实现更高级的推理和决策能力。</p><p>Schmidt进一步解释了这种扩展的实际应用，例如在科学和医学等领域中使用“链式思维”（Chain of Thought reasoning）来解决复杂问题。他举例说明了如何通过分步指导的方式，让AI系统帮助用户完成一个复杂的任务，例如制作药物的配方。通过不断地向AI系统提供新的上下文信息，AI可以生成一系列步骤来完成任务。</p><p>他认为，未来五年内，这种技术将能够生成长达一千步的复杂配方，从而在科学、医学、材料科学和气候变化等领域带来重大突破。这种能力将使AI系统能够解决以前无法解决的问题，对世界产生深远的影响。</p><h3 id="ai的补充" tabindex="-1"><a class="header-anchor" href="#ai的补充"><span>AI的补充</span></a></h3><h4 id="专业知识" tabindex="-1"><a class="header-anchor" href="#专业知识"><span>专业知识</span></a></h4><ol><li><p><strong>上下文窗口（Context Window）</strong>：在自然语言处理（NLP）和人工智能中，上下文窗口指的是AI系统在处理任务时可以同时考虑的文本或信息的范围。上下文窗口的大小决定了系统在生成回答或执行任务时能够参考的前后文信息的长度。</p></li><li><p><strong>提示（Prompt）</strong>：指用户向AI系统提供的一段文本或问题，作为AI生成响应的起点。提示可以是一个问题、指令或任何需要AI处理的信息。</p></li><li><p><strong>链式思维（Chain of Thought Reasoning）</strong>：一种推理方法，通过逐步引导AI系统完成复杂任务。每一步都基于前一步的结果，形成一个逻辑链条。这种方法有助于AI系统在处理复杂问题时保持逻辑一致性和连贯性。</p></li></ol><h4 id="思考辩论" tabindex="-1"><a class="header-anchor" href="#思考辩论"><span>思考辩论</span></a></h4><p>Eric Schmidt对上下文窗口和链式思维的讨论确实揭示了AI系统在未来可能取得的长足进展。然而，从系统设计的角度来看，以下几点需要进一步思考：</p><ol><li><p><strong>计算资源的限制</strong>：虽然无限长的上下文窗口理论上非常有吸引力，但在实际应用中，处理和存储如此大量的信息可能会面临巨大的计算资源需求。当前的硬件和算法是否能够支持这种扩展需要进一步验证。</p></li><li><p><strong>数据质量和噪音问题</strong>：随着上下文窗口的扩展，AI系统需要处理的信息量增大，这也可能引入更多的噪音和不相关信息。如何有效过滤和处理这些信息，确保系统的输出质量是一个需要解决的难题。</p></li><li><p><strong>安全和伦理问题</strong>：在科学和医学等领域，AI系统生成的长链式推理结果可能直接影响人类健康和安全。因此，如何确保AI系统在这些领域的可靠性和伦理性仍需深入探讨。</p></li></ol><h4 id="举一反三" tabindex="-1"><a class="header-anchor" href="#举一反三"><span>举一反三</span></a></h4><ol><li><p><strong>如何优化AI系统的计算资源管理，以支持更大的上下文窗口？</strong>：探讨在硬件和算法层面上，如何优化计算资源的分配和利用，以支持更大的上下文窗口而不影响系统性能。</p></li><li><p><strong>在上下文窗口扩展的同时，如何确保数据质量和减少噪音？</strong>：研究在扩展上下文窗口时，如何设计有效的数据过滤和处理机制，确保AI系统输出的准确性和相关性。</p></li><li><p><strong>AI系统在科学和医学领域应用的伦理和安全问题如何解决？</strong>：探讨在AI系统应用于科学和医学领域时，如何建立严格的伦理和安全标准，确保AI系统的决策和建议不会对人类健康和安全造成负面影响。</p></li></ol><h2 id="问题2-eric-schmidt如何看待ai代理-agents-的潜力及其可能带来的变革" tabindex="-1"><a class="header-anchor" href="#问题2-eric-schmidt如何看待ai代理-agents-的潜力及其可能带来的变革"><span>问题2 Eric Schmidt如何看待AI代理（Agents）的潜力及其可能带来的变革？</span></a></h2><h3 id="分享者的观点-1" tabindex="-1"><a class="header-anchor" href="#分享者的观点-1"><span>分享者的观点</span></a></h3><p>Eric Schmidt认为AI代理（Agents）具有巨大的潜力，并且会引发深远的变革。他首先将AI代理定义为一种能够学习新知识或掌握新技能的大型语言模型。例如，一个AI代理可以阅读所有的化学文献，提出关于化学的假设，在实验室中进行测试，然后将这些新知识添加到其数据库中。这种能力使得AI代理不仅能够处理复杂的任务，而且能够自主学习和改进。</p><p>Schmidt指出，未来会有大量的AI代理存在，数量可能达到数百万个。这些代理将会像GitHub上的代码库一样，广泛可用且功能强大。用户可以利用这些代理来解决各种问题，从简单的日常任务到复杂的科学研究。</p><p>最重要的是，Schmidt认为这些AI代理将能够相互协作，形成一个强大的网络来解决更大的问题。例如，一个由多个代理组成的团队可以共同攻克一个复杂的科学难题。这种协作能力将显著提升AI系统的效能和潜力。</p><p>然而，Schmidt也提到了潜在的风险，即当这些代理开始以我们无法理解的方式进行交流和合作时，可能会带来不可预测的后果。他建议在这种情况下，应该有措施来“拔掉插头”，即关闭这些系统，以防止它们失控。</p><p>总体而言，Eric Schmidt对AI代理的未来充满信心，认为它们将在科学、医学、材料科学和气候变化等领域带来革命性的突破。但与此同时，他也呼吁对这些技术的发展进行严格的监管和监控，以确保其安全性和可控性。</p><h3 id="ai的补充-1" tabindex="-1"><a class="header-anchor" href="#ai的补充-1"><span>AI的补充</span></a></h3><h4 id="专业知识-1" tabindex="-1"><a class="header-anchor" href="#专业知识-1"><span>专业知识</span></a></h4><ol><li><strong>AI代理（Agents）</strong>：指的是能够自主学习和执行任务的人工智能系统。它们可以根据环境中的输入做出决策，并在执行任务的过程中不断改进其性能。</li><li><strong>大型语言模型（Large Language Model）</strong>：这是指使用大量文本数据进行训练的人工智能模型，能够理解和生成自然语言。GPT-3、BERT等都是大型语言模型的例子。</li><li><strong>数据库</strong>：在此上下文中，指的是存储和管理数据的系统，AI代理可以从中获取知识并将新知识加入其中。</li><li><strong>GitHub</strong>：一个广泛使用的代码托管平台，允许开发者共享和协作开发软件项目。在此文中被用作类比，说明未来AI代理的广泛可用性和协作能力。</li></ol><h4 id="思考辩论-1" tabindex="-1"><a class="header-anchor" href="#思考辩论-1"><span>思考辩论</span></a></h4><p>从系统设计的角度来看，Eric Schmidt的观点基本上是合理的，但也存在一些需要进一步探讨的地方：</p><ol><li><strong>自主学习与改进的挑战</strong>：虽然AI代理能够自主学习和改进，但其学习过程需要大量的数据和计算资源。实现这种大规模的自主学习和改进需要克服巨大的技术和工程挑战。</li><li><strong>协作的复杂性</strong>：多个AI代理之间的协作虽然理论上可行，但实际操作中可能面临通信和协调的复杂性。不同代理可能有不同的学习算法和目标，这可能导致冲突和效率低下。</li><li><strong>拔掉插头的可行性</strong>：Schmidt提到的“拔掉插头”作为最后的安全措施，但在实际应用中，如何有效地检测和判断系统是否失控，以及如何迅速、安全地关闭系统，这些都是需要详细规划和测试的问题。</li></ol><h4 id="举一反三-1" tabindex="-1"><a class="header-anchor" href="#举一反三-1"><span>举一反三</span></a></h4><ol><li><strong>如何确保AI代理在自主学习过程中不偏离预设目标？</strong></li><li><strong>在大规模使用AI代理的环境中，如何管理和协调它们之间的通信和协作？</strong></li><li><strong>面对AI代理可能带来的伦理和法律问题，我们应该建立怎样的监管框架？</strong></li></ol><h2 id="问题3-eric-schmidt如何看待从文本到行动-text-to-action-技术的应用及其影响" tabindex="-1"><a class="header-anchor" href="#问题3-eric-schmidt如何看待从文本到行动-text-to-action-技术的应用及其影响"><span>问题3 Eric Schmidt如何看待从文本到行动（text to action）技术的应用及其影响？</span></a></h2><h3 id="分享者的观点-2" tabindex="-1"><a class="header-anchor" href="#分享者的观点-2"><span>分享者的观点</span></a></h3><p>Eric Schmidt认为从文本到行动（text to action）技术将对未来产生深远的影响。他指出，这种技术能够让用户通过简单的文字指令生成和执行复杂的程序。这意味着，未来的编程将不再需要专业的编程技能，只需用自然语言描述需求，AI系统就能自动生成相应的软件代码。</p><p>Schmidt强调，这种技术的应用将极大地提高生产效率，因为AI系统能够全天候工作，并且在某些编程语言（如Python）上的表现特别出色。他设想，这种技术结合无限长的上下文窗口和强大的AI代理，将能够处理极为复杂的任务，甚至是科学、医学和工程领域的千步操作流程。</p><p>他还提到，这种技术的发展不仅会改变编程的方式，还会引发一系列新的问题和挑战。例如，当这些系统变得足够强大时，AI代理之间的协作可能会产生出人意料的结果，甚至可能需要人为干预以确保安全。</p><p>总的来说，Schmidt对从文本到行动技术的未来充满期待，认为它将在多个领域带来革命性的变化，同时也需要密切关注其潜在的风险和挑战。</p><h3 id="ai的补充-2" tabindex="-1"><a class="header-anchor" href="#ai的补充-2"><span>AI的补充</span></a></h3><h4 id="专业知识-2" tabindex="-1"><a class="header-anchor" href="#专业知识-2"><span>专业知识</span></a></h4><ol><li><p><strong>从文本到行动（text to action）</strong>：这是一种AI技术，能够将自然语言的文字指令转化为具体的操作或程序代码。其核心是自然语言处理（NLP）和自动代码生成（code generation）技术的结合，旨在简化复杂任务的执行过程。</p></li><li><p><strong>无限长的上下文窗口</strong>：在自然语言处理和生成任务中，上下文窗口指的是模型在生成或理解文本时所能参考的前后文信息的长度。无限长的上下文窗口意味着模型可以参考整个文档或对话的所有内容，而不仅仅是有限的几句话，从而提高理解和生成的准确性。</p></li></ol><h4 id="思考辩论-2" tabindex="-1"><a class="header-anchor" href="#思考辩论-2"><span>思考辩论</span></a></h4><p>Eric Schmidt对从文本到行动技术的未来充满期待，认为它将带来革命性的变化。然而，从系统设计的角度来看，这种技术的实际应用可能面临若干挑战：</p><ol><li><p><strong>准确性和可靠性</strong>：虽然从文本到行动技术有潜力大幅提高生产效率，但其准确性和可靠性是关键问题。自然语言往往具有模糊性和多义性，如何确保生成的代码或操作完全符合用户的意图是一个重大挑战。</p></li><li><p><strong>安全性和伦理问题</strong>：当AI系统能够处理极为复杂的任务时，可能会出现意想不到的行为或结果。如何确保这些系统在执行任务时不偏离预期，避免对用户或社会造成危害，是一个需要深入研究的问题。</p></li><li><p><strong>协作与冲突</strong>：AI代理之间的协作虽然能够处理复杂任务，但也可能出现冲突或不一致的情况。这需要设计出有效的机制来协调不同代理的行为，确保系统整体的稳定性和安全性。</p></li></ol><h4 id="举一反三-2" tabindex="-1"><a class="header-anchor" href="#举一反三-2"><span>举一反三</span></a></h4><ol><li><strong>如何确保从文本到行动技术生成的代码在安全和伦理上是可接受的？</strong></li><li><strong>在处理涉及敏感数据的任务时，从文本到行动技术如何保护用户隐私？</strong></li><li><strong>如何设计AI代理之间的协作机制，以确保它们在处理复杂任务时不会产生冲突或不一致？</strong></li></ol><h2 id="问题4-eric-schmidt如何看待ai系统在未来可能变得过于强大时应采取的措施" tabindex="-1"><a class="header-anchor" href="#问题4-eric-schmidt如何看待ai系统在未来可能变得过于强大时应采取的措施"><span>问题4 Eric Schmidt如何看待AI系统在未来可能变得过于强大时应采取的措施？</span></a></h2><h3 id="分享者的观点-3" tabindex="-1"><a class="header-anchor" href="#分享者的观点-3"><span>分享者的观点</span></a></h3><p>Eric Schmidt认为，当AI系统变得过于强大，尤其是当这些系统的能力超出人类理解并开始自行决策、相互合作时，人类应采取果断措施以确保安全。他提到，当AI代理（agents）开始以我们无法理解的方式相互沟通并执行任务时，这将是一个危险的信号。在这种情况下，他建议应当采取“拔掉插头”（pull the plug）的极端措施，即关闭这些AI系统，以防止其失控并造成不可预见的危害。</p><p>Schmidt指出，这种情况并非遥不可及，而是在未来几年内就可能发生。因此，他强调了密切监控和及时应对的重要性。他认为，随着AI技术的逐步进步，政府和公司需要保持警惕，确保AI的发展在可控范围内，避免其超出人类的理解和控制。</p><p>此外，Schmidt还提到，虽然他确信这些技术进步会在未来五年内实现，但具体的时间节点并不明确，因此每个月或每六个月都需要进行能力评估和调整，以确保在技术发展过程中不会出现失控的情况。</p><h3 id="ai的补充-3" tabindex="-1"><a class="header-anchor" href="#ai的补充-3"><span>AI的补充</span></a></h3><h4 id="专业知识-3" tabindex="-1"><a class="header-anchor" href="#专业知识-3"><span>专业知识</span></a></h4><ol><li><p><strong>拔掉插头（pull the plug）</strong>：这是一个比喻，意指在某个系统或设备失控或变得危险时，通过物理或逻辑手段将其关闭。对于AI系统而言，这意味着在发现其行为超出预期或变得不可控时，采取果断措施关闭系统以避免潜在风险。</p></li><li><p><strong>能力评估和调整</strong>：这是一种持续监控和评估技术进步的方法，旨在确保技术在发展的过程中保持在可控范围内，并根据评估结果进行相应调整。对于AI系统，这意味着定期检查其性能和行为，确保其不会超出预期范围。</p></li></ol><h4 id="思考辩论-3" tabindex="-1"><a class="header-anchor" href="#思考辩论-3"><span>思考辩论</span></a></h4><p>从系统设计的角度来看，Eric Schmidt的观点存在一些值得思考的地方：</p><ol><li><p><strong>可操作性</strong>：当AI系统变得足够强大以至于人类无法理解其决策过程时，如何实际执行“拔掉插头”的操作？如果系统已经足够智能，可能会有自我保护机制，阻止被关闭。</p></li><li><p><strong>监控与评估的有效性</strong>：定期进行能力评估和调整虽然是一个好建议，但实际操作中可能面临挑战。AI系统的复杂性和不可预测性可能使得监控和评估变得困难，尤其是当系统在不断学习和进化时。</p></li><li><p><strong>伦理与法律问题</strong>：关闭一个强大的AI系统可能涉及复杂的伦理和法律问题。例如，如果该系统正在执行关键任务，关闭它可能会带来严重后果。此外，谁有权决定何时关闭系统，也是一个需要明确的问题。</p></li></ol><h4 id="举一反三-3" tabindex="-1"><a class="header-anchor" href="#举一反三-3"><span>举一反三</span></a></h4><ol><li><strong>如何在设计AI系统时嵌入安全机制，以确保在其失控时能够被安全关闭？</strong></li><li><strong>面对越来越复杂和自主的AI系统，人类应该如何调整现有的法律和伦理框架以应对潜在风险？</strong></li><li><strong>在多大程度上应该允许AI系统自主决策，以及如何设定其决策的边界？</strong></li></ol><h2 id="问题5-eric-schmidt如何看待政府在ai技术发展中的监管作用" tabindex="-1"><a class="header-anchor" href="#问题5-eric-schmidt如何看待政府在ai技术发展中的监管作用"><span>问题5 Eric Schmidt如何看待政府在AI技术发展中的监管作用？</span></a></h2><h3 id="分享者的观点-4" tabindex="-1"><a class="header-anchor" href="#分享者的观点-4"><span>分享者的观点</span></a></h3><p>Eric Schmidt认为政府在AI技术发展中的监管作用至关重要，但必须采取谨慎和合作的方式。他提出了以下几点：</p><ol><li><p><strong>信任与验证</strong>：Schmidt强调了“信任但要验证”的原则。他认为，政府应该信任技术公司，但同时也要通过独立的验证机构进行监督，以确保公司的行为符合安全和道德标准。</p></li><li><p><strong>设立信任与安全机构</strong>：他指出，西方国家的政府已经开始设立信任与安全机构，目的是监控和评估AI技术的发展。这些机构的设立是为了确保技术不会被误用，并且能够及时发现和解决潜在的安全问题。</p></li><li><p><strong>与技术公司合作</strong>：Schmidt认为，政府应与技术公司密切合作，尤其是在AI技术的研究和开发方面。他提到，西方国家的公司通常都有股东和法律诉讼的约束，这使得这些公司更有动力去遵守法律和道德规范。</p></li><li><p><strong>国际合作</strong>：他还提到，与中国等国家的合作虽然复杂且需要时间，但同样重要。他认为，全球范围内的合作对于应对AI技术的潜在威胁至关重要，因为技术的影响是全球性的。</p></li><li><p><strong>防止技术扩散</strong>：Schmidt特别关注技术扩散的问题，尤其是开源技术的扩散。他认为，政府需要制定政策，防止敏感技术落入可能会滥用它们的国家或组织手中。</p></li><li><p><strong>对抗恶意使用</strong>：他指出，技术的双重用途问题是一个重大挑战。即使是最初为善意目的开发的技术也可能被恶意使用，因此监管机构需要时刻警惕，并采取措施防止这种情况的发生。</p></li></ol><p>总的来说，Eric Schmidt认为政府在AI技术发展中的监管作用是不可或缺的，但需要通过信任与验证、设立安全机构、与技术公司合作以及国际合作等多种方式来实现。他强调，监管的目标是确保技术的安全和道德使用，同时防止其被恶意滥用。</p><h3 id="ai的补充-4" tabindex="-1"><a class="header-anchor" href="#ai的补充-4"><span>AI的补充</span></a></h3><h4 id="专业知识-4" tabindex="-1"><a class="header-anchor" href="#专业知识-4"><span>专业知识</span></a></h4><ol><li><p><strong>信任与验证（Trust but Verify）</strong>：这是一个源于冷战时期的短语，意思是虽然你可以信任某人或某事，但仍然需要进行独立的验证以确保其可信度。在AI监管中，这意味着政府和机构需要对技术公司进行独立审核和监督，以确保其行为符合安全和道德标准。</p></li><li><p><strong>双重用途技术（Dual-Use Technology）</strong>：指那些既可以用于民用目的也可以用于军事或恶意用途的技术。例如，AI可以用于医疗诊断，但也可以用于监控和军事用途。监管机构需要特别关注这些技术的使用，以防止其被滥用。</p></li><li><p><strong>开源技术（Open Source Technology）</strong>：指那些源代码公开、任何人都可以查看、修改和分发的软件或技术。虽然开源技术有助于创新和合作，但也可能导致敏感技术的扩散，增加其被恶意使用的风险。</p></li><li><p><strong>独立验证机构（Independent Verification Bodies）</strong>：这些机构独立于技术公司，负责审核和评估公司的技术和行为，确保其符合安全和道德标准。这些机构通常具有专业的技术知识和权限，能够进行深入的审查。</p></li><li><p><strong>国际合作（International Collaboration）</strong>：在AI技术的发展和监管中，各国政府和机构需要进行跨国界的合作，以应对全球性的技术挑战和威胁。这种合作可以包括信息共享、联合研究和制定共同的监管标准。</p></li></ol><h4 id="思考辩论-4" tabindex="-1"><a class="header-anchor" href="#思考辩论-4"><span>思考辩论</span></a></h4><p>从系统设计的角度来看，Eric Schmidt的观点总体上是合理的，但也存在一些潜在的挑战和逻辑漏洞：</p><ol><li><p><strong>信任与验证的实施难度</strong>：虽然“信任但要验证”是一个理想的原则，但在实际操作中，独立验证机构如何确保其完全独立和公正是一个难题。特别是当技术公司和政府之间存在利益冲突时，验证过程可能会受到干扰。</p></li><li><p><strong>技术扩散的控制</strong>：防止开源技术的扩散在现实中难以实现。开源的本质是开放和共享，限制其扩散可能会导致创新的停滞和技术发展的受限。此外，如何定义“敏感技术”以及谁来决定这些技术的敏感性也是一个复杂的问题。</p></li><li><p><strong>国际合作的复杂性</strong>：与中国等国家的合作虽然重要，但在政治和经济利益的驱动下，这种合作可能会面临重重障碍。不同国家的监管标准和法律框架可能存在显著差异，如何协调和统一这些标准是一个巨大的挑战。</p></li></ol><h4 id="举一反三-4" tabindex="-1"><a class="header-anchor" href="#举一反三-4"><span>举一反三</span></a></h4><ol><li><p><strong>AI技术的伦理问题</strong>：除了安全和道德使用，AI技术的发展还涉及到隐私、偏见和公平性等伦理问题。政府和技术公司应如何应对这些挑战？</p></li><li><p><strong>监管机制的灵活性</strong>：AI技术发展迅速，监管机制如何保持灵活性以适应技术的快速变化，同时确保安全和合规？</p></li><li><p><strong>公众参与和透明度</strong>：在AI技术的监管过程中，如何确保公众的参与和透明度，以增加公众对技术和监管的信任？</p></li></ol><h2 id="问题6-eric-schmidt如何看待全球范围内-尤其是西方国家和中国在ai技术上的竞争与合作" tabindex="-1"><a class="header-anchor" href="#问题6-eric-schmidt如何看待全球范围内-尤其是西方国家和中国在ai技术上的竞争与合作"><span>问题6：Eric Schmidt如何看待全球范围内，尤其是西方国家和中国在AI技术上的竞争与合作？</span></a></h2><h3 id="分享者的观点-5" tabindex="-1"><a class="header-anchor" href="#分享者的观点-5"><span>分享者的观点</span></a></h3><p>Eric Schmidt认为全球范围内的AI技术竞争和合作是一个复杂而重要的问题。他认为，西方国家在AI技术的发展和监管上已经采取了一些措施，而中国在AI技术上的发展也非常迅速，但在某些方面略微落后。Schmidt认为，这种竞争和合作关系需要谨慎处理，以避免潜在的风险和冲突。</p><p>具体来说，Schmidt提到：</p><ol><li><p><strong>竞争方面</strong>：</p><ul><li>西方国家（特别是美国）在AI技术的发展上投入了大量资金，拥有领先的硬件资源和技术能力。他认为，中国虽然也在快速发展AI技术，但由于缺乏顶尖的硬件支持（如高性能芯片），在某些方面会受到限制。他估计中国大约落后两年。</li><li>他提到，西方国家的科技公司如微软和谷歌，正在投入数十亿美元进行AI研究和开发，而中国的公司也在努力追赶。</li></ul></li><li><p><strong>合作方面</strong>：</p><ul><li>Schmidt认为，与中国在AI技术上的合作是必要的，尤其是在涉及全球安全和道德问题时。他提到，尽管与中国的对话目前还在初步阶段，但双方都认识到AI技术可能带来的潜在威胁，如生物武器或网络攻击。</li><li>他认为，类似于核不扩散条约的国际协议可能是必要的，以确保AI技术的安全使用。例如，他提到可以设立类似于“开放天空”条约的规则，确保双方在进行重大AI训练时互相通报，以避免误解和冲突。</li></ul></li><li><p><strong>监管和透明度</strong>：</p><ul><li>Schmidt强调了“信任但验证”的原则，他认为政府和企业需要共同努力，确保AI技术的发展是透明和可控的。他提到，西方国家的公司通常会受到严格的监管和法律约束，这有助于防止技术被滥用。</li><li>他还提到，AI技术的监管可能需要依赖AI自身，因为人类很难完全理解和控制这些复杂系统。</li></ul></li><li><p><strong>开源技术的风险</strong>：</p><ul><li>Schmidt对开源技术的快速传播表示担忧，认为这可能会使得AI技术被不法分子或敌对国家滥用。他指出，开源模型的权重和代码一旦公开，可能会被逆向工程，从而被用来开发危险应用。</li></ul></li></ol><p>总体而言，Eric Schmidt认为全球范围内的AI竞争和合作需要在透明、信任和严格监管的基础上进行，以确保技术的发展不会对全球安全产生负面影响。</p><h3 id="ai的补充-5" tabindex="-1"><a class="header-anchor" href="#ai的补充-5"><span>AI的补充</span></a></h3><h4 id="专业知识-5" tabindex="-1"><a class="header-anchor" href="#专业知识-5"><span>专业知识</span></a></h4><ol><li><p><strong>高性能芯片</strong>：高性能芯片（如GPU和TPU）是进行大量并行计算的硬件设备，对于AI模型的训练和推理至关重要。高性能芯片能够处理大量数据和复杂计算，从而加速AI算法的执行。</p></li><li><p><strong>核不扩散条约</strong>：核不扩散条约（NPT）是一个国际协议，旨在防止核武器的扩散，推动核裁军和促进和平利用核能。Schmidt提到的类似条约是指为AI技术制定国际规则，以防止其被滥用。</p></li><li><p><strong>开放天空条约</strong>：开放天空条约允许缔约国在彼此领空进行非武装侦察飞行，以增加军事透明度和信任。Schmidt提到的类似规则是指在AI训练和开发上互相通报，以避免误解和冲突。</p></li><li><p><strong>信任但验证</strong>：这一原则源于冷战时期的军备控制协议，指的是在信任对方的基础上，通过验证手段确保对方遵守协议。应用在AI领域，就是指在信任AI技术的发展和使用的同时，通过监管和检查确保其安全性。</p></li></ol><h4 id="思考辩论-5" tabindex="-1"><a class="header-anchor" href="#思考辩论-5"><span>思考辩论</span></a></h4><p>从系统设计的角度来看，Schmidt的演讲内容总体上逻辑清晰，但存在一些需要进一步思考的点：</p><ol><li><p><strong>硬件依赖性</strong>：Schmidt提到中国在AI发展上因缺乏高性能芯片而落后两年。这种评估可能过于简单，忽略了中国在算法创新和数据量上的优势。硬件只是AI发展的一个方面，软件算法和数据资源同样重要。</p></li><li><p><strong>国际合作的可行性</strong>：Schmidt建议建立类似于核不扩散条约和开放天空条约的国际协议来监管AI技术。然而，AI技术的多样性和快速发展使得制定统一的国际规则非常困难。不同国家的利益和技术水平差异也增加了达成共识的难度。</p></li><li><p><strong>开源技术的矛盾</strong>：Schmidt一方面强调开源技术的风险，另一方面又提到监管和透明度的重要性。开源技术本身是一种增加透明度的手段，完全限制开源可能会抑制创新和技术进步。如何在保护安全和促进创新之间找到平衡，是一个复杂的问题。</p></li></ol><h4 id="举一反三-5" tabindex="-1"><a class="header-anchor" href="#举一反三-5"><span>举一反三</span></a></h4><ol><li><p><strong>AI技术的伦理问题</strong>：除了技术竞争与合作，AI技术的伦理问题也是一个核心话题。如何确保AI技术不会侵犯隐私或加剧社会不平等？</p></li><li><p><strong>AI技术的军事应用</strong>：AI技术在军事领域的应用可能带来巨大的变革，同时也增加了国际冲突的风险。如何在军事领域应用AI技术的同时，避免引发新的军备竞赛？</p></li><li><p><strong>AI技术的人才培养</strong>：AI技术的发展离不开高素质的人才。各国在人才培养和教育体系上如何布局，以保持在AI领域的竞争优势？</p></li></ol><h2 id="问题7-eric-schmidt如何看待开源技术在ai发展中的优势和潜在风险" tabindex="-1"><a class="header-anchor" href="#问题7-eric-schmidt如何看待开源技术在ai发展中的优势和潜在风险"><span>问题7 Eric Schmidt如何看待开源技术在AI发展中的优势和潜在风险？</span></a></h2><h3 id="分享者的观点-6" tabindex="-1"><a class="header-anchor" href="#分享者的观点-6"><span>分享者的观点</span></a></h3><p>Eric Schmidt认为开源技术在AI发展中具有显著的优势和潜在的风险。</p><h4 id="优势" tabindex="-1"><a class="header-anchor" href="#优势"><span>优势</span></a></h4><ol><li><strong>创新与合作</strong>：开源技术促进了全球范围内的创新和合作。研究者和开发者可以基于已有的开源代码进行改进和创新，从而加速技术进步。</li><li><strong>知识共享</strong>：开源技术使得知识得以共享，降低了进入门槛，使得更多的人能够参与到前沿技术的研究和开发中。</li><li><strong>成本低廉</strong>：开源软件通常是免费的，这使得资源有限的研究机构和个人开发者也能够使用先进的技术。</li></ol><h4 id="潜在风险" tabindex="-1"><a class="header-anchor" href="#潜在风险"><span>潜在风险</span></a></h4><ol><li><strong>安全性问题</strong>：开源技术的公开性使得恶意行为者也能够获取和利用这些技术。Schmidt特别强调，开源代码和模型的权重一旦公开，便会迅速传播到全球，包括潜在的敌对国家和组织。</li><li><strong>滥用风险</strong>：Schmidt指出，开源技术可以被恶意使用。例如，面部识别技术原本是为了某些正当用途而开发的，但它也被用来监控和限制某些少数群体的自由。</li><li><strong>逆向工程</strong>：即使开源项目设置了某些“护栏”来限制不当使用，但Schmidt认为，这些限制措施相对容易被逆向工程破解，从而暴露出模型的全部潜力和风险。</li></ol><p>Schmidt总结道，尽管开源技术在推动AI发展方面具有巨大潜力，但也必须注意其可能带来的安全和滥用风险。因此，他认为需要在开源技术的使用和传播上采取更为谨慎的态度，并加强全球范围内的合作和监管，以防止其被恶意利用。</p><h3 id="ai的补充-6" tabindex="-1"><a class="header-anchor" href="#ai的补充-6"><span>AI的补充</span></a></h3><h4 id="专业知识-6" tabindex="-1"><a class="header-anchor" href="#专业知识-6"><span>专业知识</span></a></h4><ol><li><p><strong>开源技术</strong>：开源技术指的是那些其源代码公开的技术，任何人都可以查看、修改和分发这些代码。开源技术的典型代表包括操作系统Linux、编程语言Python以及机器学习框架TensorFlow等。</p></li><li><p><strong>逆向工程</strong>：逆向工程是一种通过对已有产品进行分析和研究，逆向推导出其设计原理和技术细节的过程。逆向工程常用于软件安全、漏洞研究以及技术仿制等领域。</p></li><li><p><strong>模型的权重</strong>：在机器学习中，模型的权重是指用于调整输入数据在预测过程中影响的参数。权重是通过训练过程优化得出的，代表模型对不同输入特征的敏感度。</p></li><li><p><strong>面部识别技术</strong>：面部识别技术是一种基于计算机视觉和人工智能的技术，能够通过分析人脸图像来识别人类身份。这项技术有广泛的应用，包括安全监控、身份验证和社交媒体等领域。</p></li></ol><h4 id="思考辩论-6" tabindex="-1"><a class="header-anchor" href="#思考辩论-6"><span>思考辩论</span></a></h4><p>Eric Schmidt的观点全面地讨论了开源技术在AI发展中的优势和潜在风险。然而，从系统设计的角度来看，以下几点需要进一步思考：</p><ol><li><p><strong>安全性与创新的平衡</strong>：Schmidt强调开源技术的安全性问题，但没有明确提出具体的解决方案。例如，如何在保持开源技术的开放性和创新性的同时，防止其被恶意利用？能否通过更严格的开源许可证或代码审查机制来增强安全性？</p></li><li><p><strong>滥用风险的监管措施</strong>：Schmidt提到了开源技术的滥用风险，但他并未深入探讨具体的监管措施。是否可以通过国际合作制定统一的开源技术使用规范和标准，以减少滥用的可能性？</p></li><li><p><strong>逆向工程的防护措施</strong>：Schmidt认为开源项目的限制措施容易被逆向工程破解，但未提供具体的防护策略。是否可以通过技术手段（如代码混淆、加密）或法律手段（如知识产权保护）来增强开源项目的安全性？</p></li></ol><h4 id="举一反三-6" tabindex="-1"><a class="header-anchor" href="#举一反三-6"><span>举一反三</span></a></h4><ol><li><strong>如何在保证开源技术的开放性和共享性的同时，增强其安全性和防滥用能力？</strong></li><li><strong>国际社会应如何合作制定统一的开源技术使用规范，以减少其潜在的滥用风险？</strong></li><li><strong>在面对逆向工程威胁时，开源项目应采取哪些技术和法律手段来保护其知识产权和安全性？</strong></li></ol><h2 id="问题8-eric-schmidt如何看待ai技术在未来对科学、医学、材料科学和气候变化等领域的影响" tabindex="-1"><a class="header-anchor" href="#问题8-eric-schmidt如何看待ai技术在未来对科学、医学、材料科学和气候变化等领域的影响"><span>问题8 Eric Schmidt如何看待AI技术在未来对科学、医学、材料科学和气候变化等领域的影响？</span></a></h2><h3 id="分享者的观点-7" tabindex="-1"><a class="header-anchor" href="#分享者的观点-7"><span>分享者的观点</span></a></h3><p>Eric Schmidt认为，AI技术在未来将对科学、医学、材料科学和气候变化等领域产生深远影响。他的观点如下：</p><ol><li><p><strong>科学研究的加速</strong>：</p><ul><li>Eric Schmidt指出，AI技术将能够生成复杂的、多步骤的研究流程和实验设计，例如可以生成成千上万步的科学配方。这种能力将极大地加速科学研究的进展，使研究人员能够更快地产生和验证新理论。</li></ul></li><li><p><strong>医学领域的突破</strong>：</p><ul><li>他强调，AI可以通过分析大量的医学数据和研究文献，提出新的医学假设并进行实验，从而推动医学进步。例如，AI可以帮助设计新的药物开发流程，优化治疗方案，并发现新的疾病治疗方法。</li></ul></li><li><p><strong>材料科学的创新</strong>：</p><ul><li>在材料科学领域，AI可以通过模拟和实验指导，帮助科学家发现和制造新材料。Schmidt认为，AI能大幅提升材料发现和优化的效率，推动材料科学的创新和应用。</li></ul></li><li><p><strong>应对气候变化</strong>：</p><ul><li>Eric Schmidt提到，AI技术在应对气候变化中也将发挥重要作用。AI可以帮助分析气候数据，优化能源使用和减少碳排放，设计更有效的环境保护策略，从而为气候变化的应对提供强有力的技术支持。</li></ul></li><li><p><strong>综合协作和智能化</strong>：</p><ul><li>Schmidt还认为，未来AI系统之间的协作将会变得更加智能化。例如，不同的AI代理（Agents）可以合作解决复杂的科学问题，形成一种集体智能。这种协作将进一步推动各个领域的突破和发展。</li></ul></li></ol><p>总的来说，Eric Schmidt对AI技术在上述领域的未来发展持非常乐观的态度，认为AI将成为推动科技进步和解决重大社会问题的重要工具。</p><h3 id="ai的补充-7" tabindex="-1"><a class="header-anchor" href="#ai的补充-7"><span>AI的补充</span></a></h3><h4 id="专业知识-7" tabindex="-1"><a class="header-anchor" href="#专业知识-7"><span>专业知识</span></a></h4><ol><li><p><strong>AI代理（Agents）</strong>：在人工智能领域，代理是指能够自主感知环境并采取行动以实现特定目标的计算机程序。代理系统可以是简单的规则系统，也可以是复杂的学习系统，能够在不同环境中进行优化和决策。</p></li><li><p><strong>科学研究的加速</strong>：AI可以通过自动化和优化科研过程来加速科学研究。例如，机器学习算法可以分析大量实验数据，识别潜在的研究方向，并自动生成实验设计和研究假设，从而大幅提高研究效率。</p></li><li><p><strong>医学数据分析</strong>：AI在医学领域的一个重要应用是数据分析。通过分析电子病历、基因组数据和医疗影像，AI可以发现疾病的早期迹象，预测疾病进展，并优化治疗方案。</p></li><li><p><strong>材料科学模拟</strong>：材料科学中，AI可以通过模拟不同材料的性质和行为，加速新材料的发现和优化。例如，机器学习模型可以预测材料的物理和化学性质，从而指导实验设计和材料合成。</p></li><li><p><strong>气候数据分析</strong>：AI在气候变化研究中的应用包括分析气候数据、建模气候系统和预测未来气候变化。通过结合大量气象数据和复杂的气候模型，AI可以帮助制定更有效的气候应对策略。</p></li></ol><h4 id="思考辩论-7" tabindex="-1"><a class="header-anchor" href="#思考辩论-7"><span>思考辩论</span></a></h4><p>Eric Schmidt的观点总体上非常乐观，认为AI将在多个领域带来深远影响。然而，从系统设计的角度来看，存在一些需要进一步思考和讨论的地方：</p><ol><li><p><strong>数据质量和偏差</strong>：AI系统的有效性高度依赖于训练数据的质量和多样性。如果数据存在偏差或不足，可能导致AI系统的预测和决策不准确，甚至产生负面影响。因此，在应用AI时，必须确保数据的高质量和全面性。</p></li><li><p><strong>伦理和隐私问题</strong>：特别是在医学领域，AI的应用涉及大量的敏感数据。如何保护患者隐私，确保数据安全，以及在应用过程中遵守伦理规范，是需要认真考虑的问题。</p></li><li><p><strong>系统鲁棒性和透明性</strong>：AI系统在复杂环境中的鲁棒性和透明性也是关键问题。AI系统需要在各种不同的条件下保持稳定的性能，并且其决策过程需要透明和可解释，以便人类能够信任和理解其行为。</p></li></ol><h4 id="举一反三-7" tabindex="-1"><a class="header-anchor" href="#举一反三-7"><span>举一反三</span></a></h4><ol><li><strong>如何确保AI系统在科学研究中的结果具有可重复性和可靠性？</strong></li><li><strong>在医学应用中，如何平衡AI的创新能力与患者隐私保护之间的矛盾？</strong></li><li><strong>AI在应对气候变化中的应用有哪些具体案例及其取得的成效？</strong></li></ol><hr><p><strong>信息来源</strong></p>',125),g={href:"https://www.youtube.com/watch?v=DgpYiysQjeI&t=6s",target:"_blank",rel:"noopener noreferrer"},A={href:"https://www.mix-copilot.com/",target:"_blank",rel:"noopener noreferrer"};function I(m,u){const e=r("ExternalLinkIcon");return a(),s("div",null,[c,p,d,i("ul",null,[i("li",null,[i("a",g,[t("https://www.youtube.com/watch?v=DgpYiysQjeI&t=6s"),n(e)])])]),i("p",null,[t("内容由"),i("a",A,[t("MiX Copilot"),n(e)]),t("基于大语言模型生成，有可能存在错误的风险。")])])}const b=l(h,[["render",I],["__file","The Future Of AI_ According To Former Google CEO E.html.vue"]]),x=JSON.parse('{"path":"/posts/interviews/people/%E5%9F%83%E9%87%8C%E5%85%8B%C2%B7%E6%96%BD%E5%AF%86%E7%89%B9/The%20Future%20Of%20AI_%20According%20To%20Former%20Google%20CEO%20E.html","title":"谷歌前首席执行官埃里克·施密特表示人工智能的未来 - YouTube","lang":"zh-CN","frontmatter":{"description":"前谷歌CEO埃里克·施密特在Noema杂志采访中讨论了AI的未来、何时“拔掉插头”以及如何应对中国的挑战。","date":"2024/5/29 18:42:57","head":[["meta",{"property":"og:url","content":"https://xuezhirong.com/posts/interviews/people/%E5%9F%83%E9%87%8C%E5%85%8B%C2%B7%E6%96%BD%E5%AF%86%E7%89%B9/The%20Future%20Of%20AI_%20According%20To%20Former%20Google%20CEO%20E.html"}],["meta",{"property":"og:site_name","content":"薛志荣的知识库"}],["meta",{"property":"og:title","content":"谷歌前首席执行官埃里克·施密特表示人工智能的未来 - YouTube"}],["meta",{"property":"og:description","content":"前谷歌CEO埃里克·施密特在Noema杂志采访中讨论了AI的未来、何时“拔掉插头”以及如何应对中国的挑战。"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"article:author","content":"薛志荣"}],["meta",{"property":"article:published_time","content":"2024-05-29T10:42:57.000Z"}],["meta",{"property":"og:updated_time","content":"2024-05-29T10:54:17.173Z"}],["meta",{"property":"og:modified_time","content":"2024-05-29T10:54:17.173Z"}],["meta",{"name":"twitter:title","content":"谷歌前首席执行官埃里克·施密特表示人工智能的未来 - YouTube"}],["meta",{"name":"twitter:description","content":"前谷歌CEO埃里克·施密特在Noema杂志采访中讨论了AI的未来、何时“拔掉插头”以及如何应对中国的挑战。"}],["meta",{"name":"twitter:card","content":"summary_large_image"}],["meta",{"name":"twitter:site","content":"@XueZhirong"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"谷歌前首席执行官埃里克·施密特表示人工智能的未来 - YouTube\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2024-05-29T10:42:57.000Z\\",\\"dateModified\\":null,\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"薛志荣\\"}]}"]]},"headers":[{"level":2,"title":"历史背景","slug":"历史背景","link":"#历史背景","children":[]},{"level":2,"title":"嘉宾介绍","slug":"嘉宾介绍","link":"#嘉宾介绍","children":[{"level":3,"title":"嘉宾1 Eric Schmidt","slug":"嘉宾1-eric-schmidt","link":"#嘉宾1-eric-schmidt","children":[]}]},{"level":2,"title":"问题1 Eric Schmidt如何看待上下文窗口（context window）的重要性及其未来发展？","slug":"问题1-eric-schmidt如何看待上下文窗口-context-window-的重要性及其未来发展","link":"#问题1-eric-schmidt如何看待上下文窗口-context-window-的重要性及其未来发展","children":[{"level":3,"title":"分享者的观点","slug":"分享者的观点","link":"#分享者的观点","children":[]},{"level":3,"title":"AI的补充","slug":"ai的补充","link":"#ai的补充","children":[]}]},{"level":2,"title":"问题2 Eric Schmidt如何看待AI代理（Agents）的潜力及其可能带来的变革？","slug":"问题2-eric-schmidt如何看待ai代理-agents-的潜力及其可能带来的变革","link":"#问题2-eric-schmidt如何看待ai代理-agents-的潜力及其可能带来的变革","children":[{"level":3,"title":"分享者的观点","slug":"分享者的观点-1","link":"#分享者的观点-1","children":[]},{"level":3,"title":"AI的补充","slug":"ai的补充-1","link":"#ai的补充-1","children":[]}]},{"level":2,"title":"问题3 Eric Schmidt如何看待从文本到行动（text to action）技术的应用及其影响？","slug":"问题3-eric-schmidt如何看待从文本到行动-text-to-action-技术的应用及其影响","link":"#问题3-eric-schmidt如何看待从文本到行动-text-to-action-技术的应用及其影响","children":[{"level":3,"title":"分享者的观点","slug":"分享者的观点-2","link":"#分享者的观点-2","children":[]},{"level":3,"title":"AI的补充","slug":"ai的补充-2","link":"#ai的补充-2","children":[]}]},{"level":2,"title":"问题4 Eric Schmidt如何看待AI系统在未来可能变得过于强大时应采取的措施？","slug":"问题4-eric-schmidt如何看待ai系统在未来可能变得过于强大时应采取的措施","link":"#问题4-eric-schmidt如何看待ai系统在未来可能变得过于强大时应采取的措施","children":[{"level":3,"title":"分享者的观点","slug":"分享者的观点-3","link":"#分享者的观点-3","children":[]},{"level":3,"title":"AI的补充","slug":"ai的补充-3","link":"#ai的补充-3","children":[]}]},{"level":2,"title":"问题5 Eric Schmidt如何看待政府在AI技术发展中的监管作用？","slug":"问题5-eric-schmidt如何看待政府在ai技术发展中的监管作用","link":"#问题5-eric-schmidt如何看待政府在ai技术发展中的监管作用","children":[{"level":3,"title":"分享者的观点","slug":"分享者的观点-4","link":"#分享者的观点-4","children":[]},{"level":3,"title":"AI的补充","slug":"ai的补充-4","link":"#ai的补充-4","children":[]}]},{"level":2,"title":"问题6：Eric Schmidt如何看待全球范围内，尤其是西方国家和中国在AI技术上的竞争与合作？","slug":"问题6-eric-schmidt如何看待全球范围内-尤其是西方国家和中国在ai技术上的竞争与合作","link":"#问题6-eric-schmidt如何看待全球范围内-尤其是西方国家和中国在ai技术上的竞争与合作","children":[{"level":3,"title":"分享者的观点","slug":"分享者的观点-5","link":"#分享者的观点-5","children":[]},{"level":3,"title":"AI的补充","slug":"ai的补充-5","link":"#ai的补充-5","children":[]}]},{"level":2,"title":"问题7 Eric Schmidt如何看待开源技术在AI发展中的优势和潜在风险？","slug":"问题7-eric-schmidt如何看待开源技术在ai发展中的优势和潜在风险","link":"#问题7-eric-schmidt如何看待开源技术在ai发展中的优势和潜在风险","children":[{"level":3,"title":"分享者的观点","slug":"分享者的观点-6","link":"#分享者的观点-6","children":[]},{"level":3,"title":"AI的补充","slug":"ai的补充-6","link":"#ai的补充-6","children":[]}]},{"level":2,"title":"问题8 Eric Schmidt如何看待AI技术在未来对科学、医学、材料科学和气候变化等领域的影响？","slug":"问题8-eric-schmidt如何看待ai技术在未来对科学、医学、材料科学和气候变化等领域的影响","link":"#问题8-eric-schmidt如何看待ai技术在未来对科学、医学、材料科学和气候变化等领域的影响","children":[{"level":3,"title":"分享者的观点","slug":"分享者的观点-7","link":"#分享者的观点-7","children":[]},{"level":3,"title":"AI的补充","slug":"ai的补充-7","link":"#ai的补充-7","children":[]}]}],"git":{"updatedTime":null,"contributors":[]},"filePathRelative":"posts/interviews/people/埃里克·施密特/The Future Of AI, According To Former Google CEO E.md","excerpt":"\\n<div style=\\"position: relative; width: 100%; padding-top: 56.25%;\\"><iframe src=\\"https://www.youtube.com/embed/DgpYiysQjeI\\" style=\\"position: absolute; top: 0; left: 0; width: 100%; height: 100%;\\" frameborder=\\"0\\" allow=\\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\\" referrerpolicy=\\"strict-origin-when-cross-origin\\" allowfullscreen=\\"\\"></iframe></div>"}');export{b as comp,x as data};
